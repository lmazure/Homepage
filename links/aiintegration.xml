<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="../css/strict.xsl"?>
<PAGE xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../css/schema.xsd" xml:lang="en">
<TITLE>AI integration</TITLE>
<PATH>links/aiintegration.xml</PATH>
<DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>22</DAY></DATE>
<CONTENT>
<LLIST>
  <ITEM><SLIST>
    <ITEM><BLIST><TITLE>Mess</TITLE>
      <ITEM><X><T>Replicate</T><A>https://replicate.com/home</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Amazon Bedrock</T><A>https://aws.amazon.com/bedrock/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Together AI</T><A>https://www.together.ai/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Abacus AI</T><A>https://abacus.ai/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Deep Infra</T><A>https://deepinfra.com/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Fireworks AI</T><A>https://fireworks.ai/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Hyperbolic</T><A>https://www.hyperbolic.xyz/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><BLIST><TITLE><X><T>Cohere</T><A>https://cohere.com/</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>doc</T><A>https://docs.cohere.com/docs/the-cohere-platform</A><L>en</L><F>HTML</F></X></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Libraries</TITLE>
      <ITEM><CLIST><TITLE><X><T>LangChain</T><A>https://www.langchain.com/</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>doc</T><A>https://python.langchain.com/docs/introduction/</A><L>en</L><F>HTML</F></X></ITEM>
        <ITEM><X><T>Python API</T><A>https://api.python.langchain.com/en/latest/langchain_api_reference.html</A><L>en</L><F>HTML</F></X></ITEM>
        <ITEM><X><T>source</T><A>https://github.com/langchain-ai</A><L>en</L><F>HTML</F></X></ITEM>
      </CLIST></ITEM>
      <ITEM><CLIST><TITLE><X><T>GPT4All</T><A>https://www.nomic.ai/gpt4all</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>doc</T><A>https://docs.gpt4all.io/</A><L>en</L><F>HTML</F></X></ITEM>
        <ITEM><X><T>code</T><A>https://github.com/nomic-ai/gpt4all</A><L>en</L><F>HTML</F></X></ITEM>
      </CLIST></ITEM>
      <ITEM><CLIST><TITLE><X><T>LangChain4J</T><A>https://docs.langchain4j.dev/</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>API doc</T><A>https://docs.langchain4j.dev/apidocs/index.html</A><L>en</L><F>HTML</F></X></ITEM>
        <ITEM><X><T>release notes</T><A>https://github.com/langchain4j/langchain4j/releases</A><L>en</L><F>HTML</F></X></ITEM>
        <ITEM><X><T>source</T><A>https://github.com/langchain4j</A><L>en</L><F>HTML</F></X></ITEM>
      </CLIST></ITEM>
      <ITEM><X><T>Spring AI</T><A>https://spring.io/projects/spring-ai/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><CLIST><TITLE><X><T>Griptape</T><A>https://github.com/griptape-ai/griptape</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>doc</T><A>https://docs.griptape.ai/latest/</A><L>en</L><F>HTML</F></X></ITEM>
      </CLIST></ITEM>
      <ITEM><X><T>simpleaichat</T><A>https://github.com/minimaxir/simpleaichat</A><L>en</L><F>HTML</F></X></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mess</TITLE>
      <ITEM><X><T>Learn Prompting</T><A>https://learnprompting.org/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>OpenGPTs</T><A>https://www.opengpts.org/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Open Interpreter</T><A>https://github.com/OpenInterpreter/open-interpreter</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>AutoGPT</T><A>https://github.com/Significant-Gravitas/AutoGPT</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><X><T>Docling</T><A>https://ds4sd.github.io/docling/</A><L>en</L><F>HTML</F></X></ITEM>
      <ITEM><CLIST><TITLE><X><T>llm</T><A>https://llm.datasette.io/en/stable/</A><L>en</L><F>HTML</F></X></TITLE>
        <ITEM><X><T>code</T><A>https://github.com/simonw/llm</A><L>en</L><F>HTML</F></X></ITEM>
      </CLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><CLIST><TITLE>AssemblyAI</TITLE>
      <ITEM><X><T>YouTube</T><A>https://www.youtube.com/channel/UCtatfZMf-8EkIwASXM4ts0A</A><L>en</L><F>HTML</F><FEED><A>https://www.youtube.com/feeds/videos.xml?channel_id=UCtatfZMf-8EkIwASXM4ts0A</A><F>Atom</F></FEED></X></ITEM>
    </CLIST></ITEM>
    <ITEM><CLIST><TITLE><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR></TITLE>
      <ITEM><X quality="-1"><T>YouTube</T><A>https://www.youtube.com/channel/UCpV_X0VrL8-jg3t6wYGS-1g</A><L>en</L><F>HTML</F><FEED><A>https://www.youtube.com/feeds/videos.xml?channel_id=UCpV_X0VrL8-jg3t6wYGS-1g</A><F>Atom</F></FEED></X></ITEM>
    </CLIST></ITEM>
    <ITEM><CLIST><TITLE><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR></TITLE>
      <ITEM><X quality="-1"><T>YouTube</T><A>https://www.youtube.com/channel/UCDq7SjbgRKty5TgGafW8Clg</A><L>en</L><F>HTML</F><FEED><A>https://www.youtube.com/feeds/videos.xml?channel_id=UCDq7SjbgRKty5TgGafW8Clg</A><F>Atom</F></FEED></X></ITEM>
    </CLIST></ITEM>
    <ITEM><CLIST><TITLE><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR></TITLE>
      <ITEM><X><T>YouTube</T><A>https://www.youtube.com/channel/UCyR2Ct3pDOeZSRyZH5hPO-Q</A><L>en</L><F>HTML</F><FEED><A>https://www.youtube.com/feeds/videos.xml?channel_id=UCyR2Ct3pDOeZSRyZH5hPO-Q</A><F>Atom</F></FEED></X></ITEM>
    </CLIST></ITEM>
    <ITEM><CLIST><TITLE><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Wolfe</LASTNAME></AUTHOR></TITLE>
      <ITEM><X quality="-1"><T>YouTube</T><A>https://www.youtube.com/channel/UChpleBmo18P08aKCIgti38g</A><L>en</L><F>HTML</F><FEED><A>https://www.youtube.com/feeds/videos.xml?channel_id=UChpleBmo18P08aKCIgti38g</A><F>Atom</F></FEED></X></ITEM>
    </CLIST></ITEM>
  </SLIST></ITEM>
  <ITEM><BLIST><TITLE>Articles and videos</TITLE>
    <ITEM><ARTICLE><X><T>LLaMA &amp; Alpaca: ‚ÄúChatGPT‚Äù On Your Local Computer ü§Ø |  Tutorial</T><A>https://www.youtube.com/watch?v=kT_-qUxrlOU</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>6</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Martin</FIRSTNAME><LASTNAME>Thissen</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>3</MONTH><DAY>18</DAY></DATE><COMMENT>A short explanation on how to use Dalai and LLaMA.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Hugging Face + Langchain in 5 mins | Access 200k+ FREE AI models for your AI apps</T><A>https://www.youtube.com/watch?v=_j7JEDWuqLE</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>6</MONTH><DAY>11</DAY></DATE><COMMENT>A small effective demo of using Hugging Face and LangChain.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="1"><T>$0 Embeddings (OpenAI vs. free &amp; open source)</T><A>https://www.youtube.com/watch?v=QdDoFfkVkcw</A><L>en</L><F>MP4</F><DURATION><HOUR>1</HOUR><MINUTE>24</MINUTE><SECOND>41</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Richardson</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>6</MONTH><DAY>25</DAY></DATE><COMMENT>A demo of two ways to compute embeddings: online with Hugging Face and locally in the browser.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>"Next Level Prompts?" - 10 mins into advanced prompting</T><A>https://www.youtube.com/watch?v=69bH4IHZivs</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>37</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>8</MONTH><DAY>29</DAY></DATE><COMMENT>Some tools/sites helping to write prompts: <X><T>Guidance</T><A>https://github.com/guidance-ai/guidance</A><L>en</L><F>HTML</F></X>, <X><T>FlowGPT</T><A>https://flowgpt.com/</A><L>en</L><F>HTML</F></X>, <X><T>gpt-prompt-engineer</T><A>https://github.com/mshumer/gpt-prompt-engineer</A><L>en</L><F>HTML</F></X>, <X><T>PromptsRoyale</T><A>https://www.promptsroyale.com/</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>A developer‚Äôs guide to open source LLMs and generative AI</T><ST>Open source generative AI projects are a great way to build new AI-powered features and apps.</ST><A>https://github.blog/ai-and-ml/llms/a-developers-guide-to-open-source-llms-and-generative-ai/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Gwen</FIRSTNAME><LASTNAME>Davis</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>5</DAY></DATE><COMMENT>Some information on open-source LLMs and a short list of four ones.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>ü§¨ How the #@%$! Do You Use an LLM in a SaaS Platform?</T><A>https://www.youtube.com/watch?v=fH8fJYWfJcg</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>53</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Arjan</FIRSTNAME><LASTNAME>Egges</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>6</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Arjan</FIRSTNAME><LASTNAME>Egges</LASTNAME></AUTHOR> describes his first steps to build learntail.com, using OpenAI and Langchain to generates quizzes.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Pydantic is all you need: Jason Liu</T><A>https://www.youtube.com/watch?v=yj-wSRJwrrc</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>54</SECOND></DURATION><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>1</DAY></DATE></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Liu</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>9</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Liu</LASTNAME></AUTHOR> presents his <X><T>Instructor</T><A>https://github.com/instructor-ai/instructor</A><L>en</L><F>HTML</F></X> library to structure prompting and extraction (for OpenAI).</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Embeddings: What they are and why they matter</T><A>https://simonwillison.net/2023/Oct/23/embeddings/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>23</DAY></DATE><COMMENT>A presentation of embedding and <AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR>‚Äôs small LLM tools.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>How I Fine-Tuned An AI Clone - Can You Tell The Difference?</T><A>https://www.youtube.com/watch?v=dzPsXaSl6PQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>37</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>2</DAY></DATE><COMMENT>A lengthy but too fast video just to end up with using <X><T>HeyGen</T><A>https://www.heygen.com/</A><L>en</L><F>HTML</F></X> to create a deep fake video.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>LLM: Trust, but Verify</T><ST>Understand the challenges of developing, testing, and monitoring non-deterministic software; this is a new and significant challenge for observability.</ST><A>https://dzone.com/articles/llm-trust-but-verify</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Pratik</FIRSTNAME><LASTNAME>Daga</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>3</DAY></DATE><COMMENT>The author describes the problem of model drift and proposes a mechanism to detect it.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="1"><T>An intuitive introduction to text embeddings</T><ST>Text embeddings are key to LLMs and convert text into vector coordinates.</ST><A>https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Kevin</FIRSTNAME><LASTNAME>Henner</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>9</DAY></DATE><COMMENT>A good introduction to text embedding.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Wanna RAG? These are your best LLMs!!!</T><A>https://www.youtube.com/watch?v=Ce0OKpMhvXw</A><L>en</L><F>MP4</F><DURATION><MINUTE>16</MINUTE><SECOND>10</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>16</DAY></DATE><COMMENT>A presentation of Galileo‚Äôs Hallucination Index.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>No, You DON'T NEED OpenAI Function Calling!!!!</T><A>https://www.youtube.com/watch?v=CwF-n36sB0c</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>28</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>17</DAY></DATE><COMMENT>A quick n‚Äô dirty presentation of Gorilla OpenFunctions.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Training Your Own AI Model Is Not As Hard As You (Probably) Think</T><A>https://www.youtube.com/watch?v=fCUkvL0mbxI</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Steve</FIRSTNAME><LASTNAME>Sewell</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>22</DAY></DATE><COMMENT>Using several steps to generate code from a Figma design: I wonder if what is presented here really works on other cases than this demo.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>llamafile is the new best way to run a LLM on your own computer</T><A>https://simonwillison.net/2023/Nov/29/llamafile/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>29</DAY></DATE><COMMENT>A presentation of llamafile: a single file containing the model and its executable which can run on several OSes.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Detect Texts from Documents (even SCANNED)!!!</T><A>https://www.youtube.com/watch?v=cBdZcXw44zs</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>14</DAY></DATE><COMMENT>A presentation of Surya: a tool to identify text lines and compute their bounding boxes.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Exploring ColBERT with RAGatouille</T><A>https://til.simonwillison.net/llms/colbert-ragatouille</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>27</DAY></DATE><COMMENT>Some experimentation with ColBERT, a fast retrieval model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Everything WRONG with LLM Benchmarks (ft. MMLU)!!!</T><A>https://www.youtube.com/watch?v=74Uo2HU8HBo</A><L>en</L><F>MP4</F><DURATION><MINUTE>19</MINUTE><SECOND>19</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>10</DAY></DATE><COMMENT>Presenting a paper ("<X><T>When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards</T><A>https://arxiv.org/abs/2402.01781</A><L>en</L><F>HTML</F></X>") which analyses how model‚Äôs scores are sensible to the way benchmarks are structured.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Engineering Practices for LLM Application Development</T><A>https://martinfowler.com/articles/engineering-practices-llm.html</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>David</FIRSTNAME><LASTNAME>Tan</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Jessie</FIRSTNAME><LASTNAME>Wang</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>13</DAY></DATE><COMMENT>Lessons learned from the building of a PoC of a concierge using an LLM.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>La recherche sous st√©ro√Ødes - une histoire de s√©mantique</T><A>https://www.youtube.com/watch?v=iHl3CXFkOKA</A><L>fr</L><F>MP4</F><DURATION><MINUTE>30</MINUTE><SECOND>27</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Mathilde</FIRSTNAME><LASTNAME>Rigabert</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Martin</FIRSTNAME><LASTNAME>Labenne</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>3</DAY></DATE><COMMENT>Some feedback about implementing semantic search on an e-commerce site. This could have been much shorter.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Poorman's ChatGPT-4o Works!! ü§£</T><A>https://www.youtube.com/watch?v=r70WoFqrhG8</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>0</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>15</DAY></DATE><COMMENT>A short presentation of <X><T>KingNish/OpenGPT-4o</T><A>https://huggingface.co/spaces/KingNish/OpenGPT-4o</A><L>en</L><F>HTML</F></X> a Hugging Face space supporting several modalities by using open models.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>The 4 Big Changes in LLMs</T><A>https://www.youtube.com/watch?v=Cf14BBQ-zt0</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>1</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> advices to consider four things: models are getting smarter, they are getting faster, there are getting cheaper, and context windows are getting larger.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>RouteLLM: An Open-Source Framework for Cost-Effective LLM Routing</T><A>https://lmsys.org/blog/2024-07-01-routellm/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Isaac</FIRSTNAME><LASTNAME>Ong</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Amjad</FIRSTNAME><LASTNAME>Almahairi</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Vincent</FIRSTNAME><LASTNAME>Wu</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Wei-Lin</FIRSTNAME><LASTNAME>Chiang</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Tianhao</FIRSTNAME><LASTNAME>Wu</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Joseph</FIRSTNAME><MIDDLENAME>E.</MIDDLENAME><LASTNAME>Gonzalez</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>M Waleed</FIRSTNAME><LASTNAME>Kadous</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Ion</FIRSTNAME><LASTNAME>Stoica</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>1</DAY></DATE><COMMENT>The authors propose a router that selects to run a query either toward an expensive powerfull model or toward a cheaper smaller model, in order to reduce cost while sacrifying little quality.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE predecessor="https://lmsys.org/blog/2024-07-01-routellm/"><X><T>What is an LLM Router?</T><A>https://www.youtube.com/watch?v=V_K6PCmdtRg</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>15</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>3</DAY></DATE><COMMENT>Nothing more than the previous announcement.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>InternLM - A Strong Agentic Model?</T><A>https://www.youtube.com/watch?v=DZ_KNlF1fs0</A><L>en</L><F>MP4</F><DURATION><MINUTE>18</MINUTE><SECOND>43</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>5</DAY></DATE><COMMENT>A basic presentation of <X><T>internlm/internlm2_5-7b-chat</T><A>https://huggingface.co/internlm/internlm2_5-7b-chat</A><L>en</L><F>HTML</F></X>, a model specialised for JSON and function calling.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Prompt Poet - Character AI's Prompting Framework</T><A>https://www.youtube.com/watch?v=D4b0xLKQeU4</A><L>en</L><F>MP4</F><DURATION><MINUTE>20</MINUTE><SECOND>15</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>2</DAY></DATE><COMMENT>A presentation of Prompt Poet, a Python framework to manage prompts.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Bridging the Efficiency Gap: Mastering LLM Caching for Next-Generation AI (Part 1)</T><ST>LLM caching refers to the process of storing and managing the intermediate computations and outputs generated by language models, allowing for rapid retrieval and reuse in subsequent queries or tasks. In this first part of a blog series, we'll explore the fundamental principles of LLM caching, delve into the various caching architectures and implementations that can be employed</ST><A>https://community.aws/content/2k3vKGhjWVbvtjZHf0eHc3QsATI/bridging-the-efficiency-gap-mastering-llm-caching-for-next-generation-ai-part-1</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Uri</FIRSTNAME><LASTNAME>Rosenberg</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>7</DAY></DATE><COMMENT>Some cache architectures for LLM, classical and RAG. The cache key can be exact or semantic.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE predecessor="https://community.aws/content/2k3vKGhjWVbvtjZHf0eHc3QsATI/bridging-the-efficiency-gap-mastering-llm-caching-for-next-generation-ai-part-1"><X><T>Bridging the Efficiency Gap: Mastering LLM Caching for Next-Generation AI (Part 2)</T><ST>LLM caching refers to the process of storing and managing the intermediate computations and outputs generated by language models, allowing for rapid retrieval and reuse in subsequent queries or tasks. In this second part of a blog series, we'll explore LLM caching implementations.</ST><A>https://community.aws/content/2juMSXyaSX2qelT4YSdHBrW2D6s/bridging-the-efficiency-gap-mastering-llm-caching-for-next-generation-ai-part-2</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Uri</FIRSTNAME><LASTNAME>Rosenberg</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>7</DAY></DATE><COMMENT>How to implement the previous architecture on AWS using LangChain or not.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>How streaming LLM APIs work</T><A>https://til.simonwillison.net/llms/streaming-llm-apis</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>21</DAY></DATE><COMMENT>Some experimentation of using SSE with GPT-4o Mini, Sonnet 3, and Gemini Pro using <CODEROUTINE>curl</CODEROUTINE>, Python‚Äòs <CODEROUTINE>HTTPX</CODEROUTINE>, and JavaScript‚Äôs <CODEROUTINE>fetch()</CODEROUTINE>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Is Spring AI Strong Enough for AI?</T><ST>Explore Spring's capabilities within the AI domain, its potential integration with AI libraries, and its ability to effectively manage AI workflows.</ST><A>https://dzone.com/articles/is-spring-ai-strong-enough-for-ai</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Reza</FIRSTNAME><LASTNAME>Ganji</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>27</DAY></DATE><COMMENT>This article is comparing very different things: Spring, TensorFlow Serving, Kubernetes, MLflow, and Python. Additionally, it only states some obvious facts.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Explore a New C# Library for AI</T><A>https://www.youtube.com/watch?v=Xdtm30pFt4w</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>54</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>11</DAY></DATE><COMMENT>Some very little information about <CODEROUTINE>Microsoft.Extensions.AI</CODEROUTINE>, some new .NET packages to integrate AI.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Run a prompt to generate and execute jq programs using llm-jq</T><A>https://simonwillison.net/2024/Oct/27/llm-jq/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>27</DAY></DATE><COMMENT>A new <CODEROUTINE>llm</CODEROUTINE> plugin to generate and execute <CODEROUTINE>jq</CODEROUTINE> commands.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>How Google is helping developers get better answers from AI</T><ST>Today‚Äôs guest is Logan Kilpatrick, a senior product manager at Google, who tells Ben about his journey from software engineering to machine learning to product management, all with an emphasis on reducing developer friction. They talk through the challenges of non-determinism in AI models and how Google is addressing these issues with a new feature: Grounding with Google Search. Plus, what working at the Apple Store taught Logan about product management.</ST><A>https://stackoverflow.blog/2024/11/05/how-google-is-helping-developers-get-better-answers-from-ai/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Logan</FIRSTNAME><LASTNAME>Kilpatrick</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Ben</FIRSTNAME><LASTNAME>Popper</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>5</DAY></DATE><COMMENT>There is no real information in this interview of <AUTHOR><FIRSTNAME>Logan</FIRSTNAME><LASTNAME>Kilpatrick</LASTNAME></AUTHOR>, a product manager for Google AI Studio.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>ChainForge</T><A>https://simonwillison.net/2024/Nov/8/chainforge/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>8</DAY></DATE><COMMENT>Some little information about ChainForge, a tool to evaluate prompts.</COMMENT></ARTICLE></ITEM>
    <ITEM><BLIST><TITLE>Models</TITLE>
      <ITEM><ARTICLE><X quality="1"><T>Uncensored Models</T><A>https://erichartford.com/uncensored-models</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Eric</FIRSTNAME><LASTNAME>Hartford</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>5</MONTH><DAY>15</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Eric</FIRSTNAME><LASTNAME>Hartford</LASTNAME></AUTHOR> explains how and why he fine-tunes some uncensored models.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>NEW "Orca-2" üê≥ Official Release - 13B Better than 70B Models</T><A>https://www.youtube.com/watch?v=ofJLbfyYOms</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>8</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>23</DAY></DATE><COMMENT>The title says it all (<X><T>microsoft/Orca-2-13b</T><A>https://huggingface.co/microsoft/Orca-2-13b</A><L>en</L><F>HTML</F></X>).</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Intel‚Äôs Neural Chat is Top-Ranked 7B Chat Model on the Leaderboard | Train models on CPUs</T><A>https://www.youtube.com/watch?v=EO0-dzPTa6A</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineer</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>25</DAY></DATE><COMMENT>A minimalist presentation of <X><T>Intel/neural-chat-7b-v3</T><A>https://huggingface.co/Intel/neural-chat-7b-v3</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Neural-Chat 7B: New Best 7B LLM from Intel</T><A>https://www.youtube.com/watch?v=fKx_7S0SzDA</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>20</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>27</DAY></DATE><COMMENT>An evaluation of <X><T>Intel/neural-chat-7b-v3</T><A>https://huggingface.co/Intel/neural-chat-7b-v3</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Should You Use Open Source Large Language Models?</T><A>https://www.youtube.com/watch?v=y9k-U9AuDeM</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Martin</FIRSTNAME><LASTNAME>Keen</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>27</DAY></DATE><COMMENT>A basic presentation of the LLM landscape.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Small LLM, Good Model, Bad License!!!</T><A>https://www.youtube.com/watch?v=THzmh7rvW2k</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>A basic presentation of <X><T>stabilityai/stablelm-zephyr-3b</T><A>https://huggingface.co/stabilityai/stablelm-zephyr-3b</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Mamba STRIKES again!!!</T><A>https://www.youtube.com/watch?v=LZw_mtcNlx8</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>14</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>18</DAY></DATE><COMMENT>A presentation of <X><T>state-spaces/mamba-2.8b-slimpj</T><A>https://huggingface.co/state-spaces/mamba-2.8b-slimpj</A><L>en</L><F>HTML</F></X>, a model not based on transformers.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Trust me, It's Open AI!</T><A>https://www.youtube.com/watch?v=0XQGAkCkbAI</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>19</DAY></DATE><COMMENT>A basic presentation of OpenChat 3.5.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>This Tiny Model is better than Phi 2 (somewhat!!!)</T><A>https://www.youtube.com/watch?v=dy963Nkpchs</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>46</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>21</DAY></DATE><COMMENT>A presentation of <X><T>stabilityai/stablelm-2-zephyr-1_6</T><A>https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Mambaaaa Again!!! (Mamba Hermes Tutorial)</T><A>https://www.youtube.com/watch?v=GDhcKNIuKP4</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>24</DAY></DATE><COMMENT>The usual quick ‚Äôn dirty model presentation, this time it is <X><T>clibrain/mamba-2.8b-instruct-openhermes</T><A>https://huggingface.co/clibrain/mamba-2.8b-instruct-openhermes</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>The EASIEST Local LLM App (OpenAI-compatible API)!!!</T><A>https://www.youtube.com/watch?v=hX8pt_drIck</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>42</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>28</DAY></DATE><COMMENT>A presentation of Jan, yet another tool to run chat models locally.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>RNN just outperformed TRANSFORMERS!!!</T><A>https://www.youtube.com/watch?v=gHdRgfmAVIw</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>29</DAY></DATE><COMMENT>A presentation of <X><T>RWKV/v5-Eagle-7B</T><A>https://huggingface.co/RWKV/v5-Eagle-7B-pth</A><L>en</L><F>HTML</F></X>, a RWKV model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Very small vision language model!!! (MoonDream V1)</T><A>https://www.youtube.com/watch?v=1b9erAtYr9A</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>29</DAY></DATE><COMMENT>A quick ‚Äôn dirty presentation of <X><T>vikhyatk/moondream1</T><A>https://huggingface.co/vikhyatk/moondream1</A><L>en</L><F>HTML</F></X>, a small vision language model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>This VLM can be your MultiModal AI with less than 6GB Memory!!!</T><A>https://www.youtube.com/watch?v=_BzWviKLtxg</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>49</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>5</DAY></DATE><COMMENT>A demonstration of moondream2, a small vision model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>The RAG King üëë goes HUGE!!!</T><A>https://www.youtube.com/watch?v=Knjc25bPn3w</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>4</DAY></DATE><COMMENT><X><T>CohereForAI/c4ai-command-r-plus</T><A>https://huggingface.co/CohereForAI/c4ai-command-r-plus</A><L>en</L><F>HTML</F></X></COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Apple releases eight small AI language models aimed at on-device use</T><ST>OpenELM mirrors efforts by Microsoft to make useful small AI language models that run locally.</ST><A>https://arstechnica.com/information-technology/2024/04/apple-releases-eight-small-ai-language-models-aimed-at-on-device-use/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>25</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>MASSIVE Leap for LLama3! OpenChat's 3.6 8B Model Obliterates LLama3 8B!</T><A>https://www.youtube.com/watch?v=-j4CQS6dGtc</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>27</DAY></DATE><COMMENT>A botched evaluation of <X><T>openchat/openchat-3.6-8b</T><A>https://huggingface.co/openchat/openchat-3.6-8b-20240522</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>ChatTTS -  Conversational TTS Step by Step</T><A>https://www.youtube.com/watch?v=L4klnZ5Lox8</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>13</DAY></DATE><COMMENT>A presentation of ChatTTS, a text to speech model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Nemotron-4 340B - Need to Make a LLM Dataset?</T><A>https://www.youtube.com/watch?v=Pk0VzEwjYos</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>16</DAY></DATE><COMMENT>A presentation of the Nemotron models which are usable to generate synthetic data.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Introducing The New Champion of Function Calling!</T><A>https://www.youtube.com/watch?v=A2YnVQ1T3Lg</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>18</DAY></DATE><COMMENT>A presentation of <X><T>Groq/Llama-3-Groq-8B-Tool-Use</T><A>https://huggingface.co/Groq/Llama-3-Groq-8B-Tool-Use</A><L>en</L><F>HTML</F></X> and <X><T>Groq/Llama-3-Groq-70B-Tool-Use</T><A>https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use</A><L>en</L><F>HTML</F></X>, models based on Llama 3 specialised for function calling.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Best Open Source Text-to-Speech AI Tutorial in 2024</T><A>https://www.youtube.com/watch?v=STuEJLBLvoc</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>44</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>18</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR> demoes Parler-TTS.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>The Ultimate Writing Challenge: Longwriter Tackles 10,000 Words In One Sitting</T><A>https://www.youtube.com/watch?v=6cubCIupyik</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>30</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> presents <X><T>THUDM/LongWriter-glm4-9b</T><A>https://huggingface.co/THUDM/LongWriter-glm4-9b</A><L>en</L><F>HTML</F></X> and <X><T>THUDM/LongWriter-llama3.1-8b</T><A>https://huggingface.co/THUDM/LongWriter-llama3.1-8b</A><L>en</L><F>HTML</F></X>, two models fine-tuned for generating long output.</COMMENT></ARTICLE></ITEM>
      <ITEM><BLIST><TITLE>Mistral</TITLE>
        <ITEM><ARTICLE><X><T>SDS 778: Mixtral 8x22B: SOTA Open-Source LLM Capabilities at a Fraction of the Compute</T><A>https://www.superdatascience.com/podcast/mixtral-8x22b-sota-open-source-llm-capabilities-at-a-fraction-of-the-compute</A><L>en</L><F>MP3</F><DURATION><MINUTE>6</MINUTE><SECOND>52</SECOND></DURATION></X><X><T>778: Mixtral 8x22B: SOTA Open-Source LLM Capabilities at a Fraction of the Compute ‚Äî with Jon Krohn</T><A>https://www.youtube.com/watch?v=8i5s7DFAjek</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jon</FIRSTNAME><LASTNAME>Krohn</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>26</DAY></DATE><COMMENT>An overview of the open-weights Mistral‚Äôs models.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Build, tweak, repeat</T><ST>Making it easier to develop and share generative AI applications.</ST><A>https://mistral.ai/news/build-tweak-repeat/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral introduces fine-tuning and an alpha version of agents.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>AI in abundance</T><ST>Introducing a free API, improved pricing across the board, a new enterprise-grade Mistral Small, and free vision capabilities on le Chat.</ST><A>https://mistral.ai/fr/news/september-24-release/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>A new free tier, a price cut, an update of Mistral Small, and Pixtral available on le Chat.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE predecessor="https://mistral.ai/fr/news/september-24-release/"><X quality="-1"><T>Mistral AI price cuts!!</T><A>https://www.youtube.com/watch?v=-Of4p2yOdQY</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>36</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>Reading Mistral‚Äôs announcement.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Mistral Batch API</T><ST>Lower cost API for AI builders.</ST><A>https://mistral.ai/news/batch-api/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral introduces a batch mode which is 50% cheaper than the synchronous mode.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Mistral Moderation API</T><ST>We are introducing our new moderation service enabling our users to detect undesirable text content along several policy dimensions.</ST><A>https://mistral.ai/news/mistral-moderation/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral proposes an API to classify raw test or chat according to nine categories (Sexual, Hate and Discrimination, Violence and Threats, Dangerous and Criminal Content, Self-Harm, Health, Financial, Law, and PII).</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Mistral has entered the chat</T><ST>Search, vision, ideation, coding‚Ä¶ all yours for free.</ST><A>https://mistral.ai/fr/news/mistral-chat/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT>Le chat has some new features: web search, canvas, and integration of Pixtral Large.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X quality="-1"><T>Mistral's FREE Coding Canvas, Search &amp; Image Gen: This BEATS Claude &amp; ChatGPT for FULLY FREE!</T><A>https://www.youtube.com/watch?v=WlRoF24bwL4</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR> performs some very basic experimentation with the new Mistral‚Äôs chat.</COMMENT></ARTICLE></ITEM>
        <ITEM><BLIST><TITLE>Mistral 7B</TITLE>
          <ITEM><ARTICLE><X><T>Is it really the best 7B model? (A First Look)</T><A>https://www.youtube.com/watch?v=3SdopNwQJ-c</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Mƒ±sra</FIRSTNAME><LASTNAME>Turp</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>9</MONTH><DAY>29</DAY></DATE><COMMENT>A short presentation of Mistral 7B model.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>ü§´UNCENSORED Mistral can answer ANYTHING ü§´</T><A>https://www.youtube.com/watch?v=YPOpzJ4N25w</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>51</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>14</DAY></DATE><COMMENT>Testing <X><T>ehartford/dolphin-2.0-mistral-7b</T><A>https://huggingface.co/cognitivecomputations/dolphin-2.0-mistral-7b</A><L>en</L><F>HTML</F></X> in Google Colab.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>NOW, Zephyr 7B on Free Colab (W/o Quantization)</T><A>https://www.youtube.com/watch?v=c_S_KGRUzoY</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>5</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>17</DAY></DATE><COMMENT>How to use a sharded version of <X><T>HuggingFaceH4/zephyr-7b-alpha</T><A>https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha</A><L>en</L><F>HTML</F></X> in Google Collab.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>FULLY LOCAL Mistral AI PDF Processing [Hands-on Tutorial]</T><A>https://www.youtube.com/watch?v=wZDVgy_14PE</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>18</DAY></DATE><COMMENT>The guy is just doing the example of <X><T>katanaml/llm-mistral-invoice-cpu</T><A>https://github.com/katanaml/llm-mistral-invoice-cpu</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mistral AI's Open Source Initiative | Arthur Mensch, Mistral AI | #aiPULSE 2023</T><A>https://www.youtube.com/watch?v=5fNtOsu3YvQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>29</MINUTE><SECOND>41</SECOND></DURATION><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>6</DAY></DATE></X><AUTHOR><FIRSTNAME>Arthur</FIRSTNAME><LASTNAME>Mensch</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>17</DAY></DATE><COMMENT>The reason for creating a 7B model and some little information about its implementation.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>Mistral 7B v0.2 Base: New Mistral Secrets Released at SF AI Hackathon?</T><A>https://www.youtube.com/watch?v=62gpF6Uq6Rc</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>3</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>24</DAY></DATE><COMMENT>Mistral has released a new version of their small foundation model for their San Francisco Hackathon.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>The CRAZIEST LLM Fine-Tuning I've seen, And It WORKS!!!</T><A>https://www.youtube.com/watch?v=YaXAzyUR0mE</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>27</DAY></DATE><COMMENT>The Hackathon winner: Mistral 7B fine-tuned to play Doom. But this presentation is a bad as usual.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>NEW Mistral-7B v0.3 üá´üá∑ TESTED:  Uncensored, Function Calling, faster than llama3 8b?!</T><A>https://www.youtube.com/watch?v=H-vMf2VF2po</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>22</DAY></DATE><COMMENT>An inconclusive test of the latest version of Mistral-7B.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mistral's new 7B Model with Native Function Calling</T><A>https://www.youtube.com/watch?v=0T1444HJbt0</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>24</DAY></DATE><COMMENT>A better presentation of the model.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Mixtral 8x7B</TITLE>
          <ITEM><ARTICLE><X><T>Mistral AI Trolls Google With 87GB T*rrent (Beats GPT4)</T><A>https://www.youtube.com/watch?v=wemHDMh2I8c</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>Mistral posted a torrent file for their new model, a MoE 8x7B.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mistral AI bucks release trend by dropping torrent link to new open source LLM</T><A>https://venturebeat.com/ai/mistral-ai-bucks-release-trend-by-dropping-torrent-link-to-new-open-source-llm/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Sharon</FIRSTNAME><LASTNAME>Goldman</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>The same.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>How To Run Mistral 8x7B LLM AI RIGHT NOW! (nVidia and Apple M1)</T><A>https://www.youtube.com/watch?v=5v_YhF6y_1c</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>29</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>10</DAY></DATE><COMMENT>People start to play with the model.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mixtral of experts</T><ST>A high quality Sparse Mixture-of-Experts.</ST><A>https://mistral.ai/news/mixtral-of-experts/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>11</DAY></DATE><COMMENT>The official announcement.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mixtral 8x7B üá´üá∑ Released! - FASTEST SMoE 7B LLM on Earth üåéüî•</T><A>https://www.youtube.com/watch?v=00vj2goPlPg</A><L>en</L><F>MP4</F><DURATION><MINUTE>7</MINUTE><SECOND>26</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>12</DAY></DATE><COMMENT>Yet another presentation of Mixtral 8x7B.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>Mixtral 8x MoE vs Llama 2 70B vs Zephyr 7B vs GPT 3.5 Turbo</T><A>https://www.youtube.com/watch?v=ICYUSTwzYaU</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>12</DAY></DATE><COMMENT>A quick ‚Äôn dirty comparison of the four models.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>The NEW Mixtral 8X7B Paper is GENIUS!!!</T><A>https://www.youtube.com/watch?v=8XTHLhwX0UQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>9</DAY></DATE><COMMENT>Yet another botched presentation of a paper, this time it is "<X><T>Mixtral of Experts</T><A>https://arxiv.org/abs/2401.04088</A><L>en</L><F>HTML</F></X>".</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Mixtral of Experts (Paper Explained)</T><A>https://www.youtube.com/watch?v=mwO6v4BlgZQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>34</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Yannic</FIRSTNAME><LASTNAME>Kilcher</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>13</DAY></DATE><COMMENT>A better presentation of the same paper.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Mixtral 8x22B</TITLE>
          <ITEM><ARTICLE><X quality="-1"><T>Mistral does it again!!!</T><A>https://www.youtube.com/watch?v=6CgeLwYUghE</A><L>en</L><F>MP4</F><DURATION><MINUTE>4</MINUTE><SECOND>44</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>10</DAY></DATE><COMMENT>The usual botched announcement of Mistral‚Äôs new model: <X><T>mistral-community/Mixtral-8x22B-v0.1</T><A>https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>NEW Mixtral 8x22b Tested - Mistral's New Flagship MoE Open-Source Model</T><A>https://www.youtube.com/watch?v=a75TC-w2aQ4</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matthew</FIRSTNAME><LASTNAME>Berman</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>13</DAY></DATE><COMMENT>A classic naive evaluation of the model.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>MIXTRAL 8x22B INSTRUCT and more!!!</T><A>https://www.youtube.com/watch?v=nKst30LrgC4</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>17</DAY></DATE><COMMENT>The Mixtral 8x22B Instruct model, a tokenizer, and a Python library: Mistral Common.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Codestral</TITLE>
          <ITEM><ARTICLE><X><T>Codestral: Hello, World!</T><ST>Empowering developers and democratising coding with Mistral AI.</ST><A>https://mistral.ai/news/codestral/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>29</DAY></DATE><COMMENT>Mistral announces their first code model.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>Solving HackerRank HARD Problems with Codestral.</T><A>https://www.youtube.com/watch?v=MJ7W45iHAks</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>28</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>4</DAY></DATE><COMMENT>The too common evaluation of a code model: the evaluator simply copies and pastes the problem and runs the unit tests, without looking at the generated code.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Mathstral</TITLE>
          <ITEM><ARTICLE><X><T>MathŒ£tral</T><ST>As a tribute to Archimedes, whose 2311th anniversary we‚Äôre celebrating this year, we are proud to release our first Mathstral model, a specific 7B model designed for math reasoning and scientific discovery. The model has a 32k context window published under the Apache 2.0 license.</ST><A>https://mistral.ai/news/mathstral/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>16</DAY></DATE><COMMENT>Mistral announces an evolution of Mistral 7B targeted at solving math problems.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Codestral Mamba</TITLE>
          <ITEM><ARTICLE><X><T>Codestral Mamba</T><ST>As a tribute to Cleopatra, whose glorious destiny ended in tragic snake circumstances, we are proud to release Codestral Mamba, a Mamba2 language model specialised in code generation, available under an Apache 2.0 license.</ST><A>https://mistral.ai/fr/news/codestral-mamba/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>16</DAY></DATE><COMMENT>The subtitle says it all.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Mistral Large 2</TITLE>
          <ITEM><ARTICLE><X><T>Mistral Large 2</T><A>https://simonwillison.net/2024/Jul/24/mistral-large-2/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>24</DAY></DATE><COMMENT>Some short notes.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>Welcome Mistral Large 2 !!!</T><A>https://www.youtube.com/watch?v=_K79cA1KW_Y</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>24</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR> is doing his usual basic scanning though the announcement.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Pixtral</TITLE>
          <ITEM><ARTICLE><X><T>Pixtral-12B üëÄ: Mistral AI's First Multi-Modal VLLM is HERE!</T><A>https://www.youtube.com/watch?v=PfzPfB3esG4</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>29</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>11</DAY></DATE><COMMENT>The model announcement.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Ministral 3B &amp; 8B</TITLE>
          <ITEM><ARTICLE><X><T>Ministral 8B: MistralAI just released NEW 3b and 8b Agentic Models!</T><A>https://www.youtube.com/watch?v=wxl6ltSCbiM</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>34</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>16</DAY></DATE><COMMENT>The usual basic reading of the model announcement.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Pixtral Large</TITLE>
          <ITEM><ARTICLE><X><T>Pixtral Large</T><ST>Pixtral grows up.</ST><A>https://mistral.ai/fr/news/pixtral-large/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT>A new vision model based on Mistral Large 2.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Gemma</TITLE>
        <ITEM><ARTICLE><X><T>Google beats OpenAI in "Open Sourcing" Flagship Models!</T><A>https://www.youtube.com/watch?v=UM2arC3EzEI</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>0</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>21</DAY></DATE><COMMENT>Google has released two open-weight models: Gemma 2B and 7B.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>How to run Google Gemma? (Free GPU!)</T><A>https://www.youtube.com/watch?v=6W_aJCQFpbg</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>55</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>21</DAY></DATE><COMMENT>How to use the Gemma models on Kaggle.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X quality="-1"><T>11 Learnings from Google Gemma Technical Paper</T><A>https://www.youtube.com/watch?v=AUNuS_EXxjo</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>34</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>22</DAY></DATE><COMMENT>A usual quick ‚Äôn dirty presentation of a paper.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Finetuning Gemma 2B (w/ Example Colab Code)</T><A>https://www.youtube.com/watch?v=w4jkWkmmUHE</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Adithya</FIRSTNAME><LASTNAME>S K</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>24</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Gemma 2 - Google's New 9B and 27B Open Weights Models</T><A>https://www.youtube.com/watch?v=xxCkuxQuT_g</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>29</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>27</DAY></DATE><COMMENT>A presentation of the two models and a short quick evaluation.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Google just dropped Gemma 2 2B!</T><A>https://www.youtube.com/watch?v=axWSZ5WcSAQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>36</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>31</DAY></DATE><COMMENT>A short presentation of the model and some ways to use it.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Llama</TITLE>
        <ITEM><ARTICLE><X quality="-1"><T>Meta AI launches CodeLlama 70B!!!</T><A>https://www.youtube.com/watch?v=IKgQKQeMDvE</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>57</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>29</DAY></DATE><COMMENT>Meta released Code Llama (<X><T>codellama/CodeLlama-70b-hf</T><A>https://huggingface.co/codellama/CodeLlama-70b-hf</A><L>en</L><F>HTML</F></X>).</COMMENT></ARTICLE></ITEM>
        <ITEM><BLIST><TITLE>Llama 3</TITLE>
          <ITEM><ARTICLE><X><T>Llama-3 is here!!!</T><A>https://www.youtube.com/watch?v=NRHIkyjfHUg</A><L>en</L><F>MP4</F><DURATION><MINUTE>5</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>18</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>How to Download Llama 3 Models (8 Easy Ways to access Llama-3)!!!!</T><A>https://www.youtube.com/watch?v=KyrYOKamwOk</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>18</DAY></DATE><COMMENT>Several methods to play with Llama 3.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Options for accessing Llama 3 from the terminal using LLM</T><A>https://simonwillison.net/2024/Apr/22/llama-3/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>22</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>What‚Äôs up with Llama 3? Arena data analysis</T><A>https://lmsys.org/blog/2024-05-08-llama3/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Lisa</FIRSTNAME><LASTNAME>Dunlap</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Evan</FIRSTNAME><LASTNAME>Frick</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Tianle</FIRSTNAME><LASTNAME>Li</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Isaac</FIRSTNAME><LASTNAME>Ong</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Joseph</FIRSTNAME><MIDDLENAME>E.</MIDDLENAME><LASTNAME>Gonzalez</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Wei-Lin</FIRSTNAME><LASTNAME>Chiang</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>8</DAY></DATE><COMMENT>An analysis on how Llama 3-70B compares to the other major LLMs depending on the topic, complexity, sentiment‚Ä¶</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Llama 3.1</TITLE>
          <ITEM><ARTICLE><X><T>üî• Llama 3.1 405B Benchmarks are INSANE!!!</T><A>https://www.youtube.com/watch?v=t8qYTJHdEEQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>38</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>22</DAY></DATE><COMMENT>Llama 3.1 may have been leaked or this is maybe a fake.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Llama 3.1-405B Model LEAKED! New Benchmarks Hint at GPT-4o Takedown?</T><A>https://www.youtube.com/watch?v=aSr3u4VYbio</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>22</DAY></DATE><COMMENT>The same.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X quality="-1"><T>LLama 3.1 405B - A very large LLM!</T><A>https://www.youtube.com/watch?v=adZuWYJmHOc</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>23</DAY></DATE><COMMENT>The real announcement has arrived, <AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR> is doing his usual basic reading of it.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>How to Access Llama 3.1 LLMs</T><A>https://www.youtube.com/watch?v=R_vrjOkGvZ8</A><L>en</L><F>MP4</F><DURATION><MINUTE>4</MINUTE><SECOND>36</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>23</DAY></DATE><COMMENT>Some ways to use Llama 3.1.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>The Big Fat Llama has arrived - Llama-3.1-405B</T><A>https://www.youtube.com/watch?v=STp-xHmRSeE</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>10</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>23</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> is doing his usual model presentation and quick evaluation.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Llama 405b: Full 92 page Analysis, and Uncontaminated SIMPLE Benchmark Results</T><A>https://www.youtube.com/watch?v=Tf1nooXtUHE</A><L>en</L><F>MP4</F><DURATION><MINUTE>26</MINUTE><SECOND>49</SECOND></DURATION></X><AUTHOR><GIVENNAME>AI Explained</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>24</DAY></DATE><COMMENT>Some information extracted from the technical paper.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
        <ITEM><BLIST><TITLE>Llama 3.2</TITLE>
          <ITEM><ARTICLE><X><T>Llama 3.2</T><A>https://simonwillison.net/2024/Sep/25/llama-32/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>25</DAY></DATE><COMMENT>Some little information and feedback about the new models.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Llama 3.2 goes Multimodal and to the Edge</T><A>https://www.youtube.com/watch?v=0iznczNq0UQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>8</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>26</DAY></DATE><COMMENT>A reading of the announcement and demonstrating the speed of the small language models.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>SDS 824: Llama 3.2: Open-Source Edge and Multimodal LLMs</T><A>https://www.superdatascience.com/podcast/824</A><L>en</L><F>MP3</F><DURATION><MINUTE>13</MINUTE><SECOND>35</SECOND></DURATION></X><X><T>824: Llama 3.2: Open-Source Edge and Multimodal LLMs ‚Äî with Jon Krohn (@JonKrohnLearns)</T><A>https://www.youtube.com/watch?v=tLDee5AKWUI</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jon</FIRSTNAME><LASTNAME>Krohn</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>4</DAY></DATE><COMMENT>An overview of the Llama 3.2 release.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Phi</TITLE>
        <ITEM><ARTICLE><X><T>Microsoft‚Äôs Phi-3 shows the surprising power of small, locally run AI language models</T><ST>Microsoft‚Äôs 3.8B parameter Phi-3 may rival GPT-3.5, signaling a new era of ‚Äúsmall language models."</ST><A>https://arstechnica.com/information-technology/2024/04/microsofts-phi-3-shows-the-surprising-power-of-small-locally-run-ai-language-models/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>23</DAY></DATE><COMMENT>Some little information, mostly Microsoft‚Äôs PR, on Phi-3-mini.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Testing Microsoft's New VLM - Phi-3 Vision</T><A>https://www.youtube.com/watch?v=iz2rXDLyBHU</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>52</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>7</DAY></DATE><COMMENT>A presentation of a small test of Phi-3 Vision.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Microsoft's Phi 3.5 - The latest SLMs</T><A>https://www.youtube.com/watch?v=wVuwTeW4Ow4</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>21</DAY></DATE><COMMENT>A <AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR>‚Äôs classical presentation and short experimentation with the models.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Qwen</TITLE>
        <ITEM><ARTICLE><X><T>China's RELENTLESS with new AI (Qwen 1.5) LLMs!!!</T><A>https://www.youtube.com/watch?v=THRJNJy90CQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>55</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>5</DAY></DATE><COMMENT>Alibaba has released <X><T>many Qwen1.5 models</T><A>https://huggingface.co/collections/Qwen/qwen15-65c0a2f577b1ecb76d786524</A><L>en</L><F>HTML</F></X> of different sizes.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen 2 - For Reasoning or Creativity?</T><A>https://www.youtube.com/watch?v=UUylYfR4Kbs</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>45</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>10</DAY></DATE><COMMENT>A presentation and a dubious test of Qwen 2.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Deepseek</TITLE>
        <ITEM><ARTICLE><X><T>The NEW BEST Base LLM??? (DeepSeek LLM)</T><A>https://www.youtube.com/watch?v=r_Eg0JUFqrU</A><L>en</L><F>MP4</F><DURATION><MINUTE>16</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>29</DAY></DATE><COMMENT>A basic presentation of <X><T>deepseek-ai/deepseek-llm-7b-chat</T><A>https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Deepseek-R1-Lite (Tested): This OPENSOURCE Model BEATS O1 &amp; CLAUDE 3.5 SONNET!?</T><A>https://www.youtube.com/watch?v=UIrjc_f4icg</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>20</DAY></DATE><COMMENT>A quick simplistic evaluation of DeepSeek R1.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>RAG</TITLE>
      <ITEM><ARTICLE><X><T>ClippyGPT - How I Built Supabase‚Äôs OpenAI Doc Search (Embeddings)</T><A>https://www.youtube.com/watch?v=Yhtjd7yGGGA</A><L>en</L><F>MP4</F><DURATION><MINUTE>41</MINUTE><SECOND>51</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Richardson</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>2</MONTH><DAY>7</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Richardson</LASTNAME></AUTHOR> describes in details how he implemented a chat to answer questions on Supabase: tokenising the doc, finding the paragraph closest to the question, and generating the answer.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="1"><T>Build RAG Application Using a LLM Running on Local Computer with GPT4All and Langchain</T><ST>Privacy-preserving LLM without GPU</ST><A>https://medium.com/rahasak/build-rag-application-using-a-llm-running-on-local-computer-with-gpt4all-and-langchain-13b4b8851db8</A><L>en</L><F>HTML</F></X><AUTHOR><GIVENNAME>(Œªx.x)eranga</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>10</DAY></DATE><COMMENT>A clear explanation with working code of how to scrap an Internet doc, to chunk it, to store it in Chroma, and to use GPT4All to generate the answer.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Ne mettez pas les projets RAG en production trop vite !</T><A>https://blog.octo.com/la-plupart-des-projets-llm-ne-sont-pas-pret-pour-une-mise-en-production</A><L>fr</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Philippe</FIRSTNAME><LASTNAME>Prados</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>3</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Philippe</FIRSTNAME><LASTNAME>Prados</LASTNAME></AUTHOR> lists some examples of problems that will occur with a too simplistic implementation of a RAG. But this simply means that you do not design a demo and a scalable application the same way, the second is much more complex.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE predecessor="https://blog.octo.com/la-plupart-des-projets-llm-ne-sont-pas-pret-pour-une-mise-en-production"><X><T>Rendre r√©silient un projet RAG</T><A>https://blog.octo.com/octo-rendre-resilient-un-projet-rag</A><L>fr</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Philippe</FIRSTNAME><LASTNAME>Prados</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>17</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Philippe</FIRSTNAME><LASTNAME>Prados</LASTNAME></AUTHOR> suggested many changes to LangChain in order to make it more resilient, e.g. to properly support transactions.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Breaking up is hard to do: Chunking in RAG applications</T><ST>A look at some of the current thinking around chunking data for retrieval-augmented generation (RAG) systems.</ST><A>https://stackoverflow.blog/2024/06/06/breaking-up-is-hard-to-do-chunking-in-rag-applications/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Ryan</FIRSTNAME><LASTNAME>Donovan</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>6</DAY></DATE><COMMENT>A high level presentation of some chunking methods and how to evaluate them.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Supercharging RAG with Generative Feedback Loops from Weaviate</T><A>https://www.youtube.com/watch?v=ijCjKnbQgXc</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>7</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Letitia</FIRSTNAME><LASTNAME>Parcalabescu</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>17</DAY></DATE><COMMENT>A presentation of Generative Feedback Loops, which is just about storing LLM generated text in a vectorial database, so it be retrieved quickly rather than regenerated by the LLM.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Building search-based RAG using Claude, Datasette and Val Town</T><A>https://simonwillison.net/2024/Jun/21/search-based-rag/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>21</DAY></DATE><COMMENT>The debrief of a life session of implementing a small RAG in Val Town.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools (Paper Explained)</T><A>https://www.youtube.com/watch?v=no7EQkOiHQM</A><L>en</L><F>MP4</F><DURATION><HOUR>1</HOUR><MINUTE>11</MINUTE><SECOND>57</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Yannic</FIRSTNAME><LASTNAME>Kilcher</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>26</DAY></DATE><COMMENT>A critic of "<X><T>Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools</T><A>https://arxiv.org/abs/2405.20362</A><L>en</L><F>HTML</F></X>".</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Gemma 2 - Local RAG with Ollama and LangChain</T><A>https://www.youtube.com/watch?v=daZOrbMs61I</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>42</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>28</DAY></DATE><COMMENT>A simple RAG implementation.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Practical tips for retrieval-augmented generation (RAG)</T><ST>Retrieval-augmented generation (RAG) is one of the best (and easiest) ways to specialize an LLM over your own data, but successfully applying RAG in practice involves more than just stitching together pretrained models.</ST><A>https://stackoverflow.blog/2024/08/15/practical-tips-for-retrieval-augmented-generation-rag/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Cameron</FIRSTNAME><MIDDLENAME>R.</MIDDLENAME><LASTNAME>Wolfe</LASTNAME><NAMESUFFIX>PhD</NAMESUFFIX></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>15</DAY></DATE><COMMENT>Some high level advice on how to implement RAG.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Knowledge Graphs: The Secret Weapon for Superior RAG Applications</T><ST>Integrating knowledge graphs in RAG applications enhances recommendation accuracy and context-awareness, providing structured, interconnected data.</ST><A>https://dzone.com/articles/knowledge-graphs-the-secret-weapon-for-rag-apps</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Pavan</FIRSTNAME><LASTNAME>Vemuri</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Prince</FIRSTNAME><LASTNAME>Bose</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Tharakarama</FIRSTNAME><MIDDLENAME>Reddy</MIDDLENAME><LASTNAME>Yernapalli Sreenivasulu</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>19</DAY></DATE><COMMENT>This article is only about the data retrieval. The data needs to be structured, so it can be stored as a semantic graph.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>RAG vs. Fine Tuning</T><A>https://www.youtube.com/watch?v=00Q0G84kq3M</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>56</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Cedric</FIRSTNAME><LASTNAME>Clyburn</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>9</DAY></DATE><COMMENT>The basics of RAG vs. fine-tuning, and a description of combining both.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Contextual RAG is stupidly brilliant!</T><A>https://www.youtube.com/watch?v=42Da0O9zkhc</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>23</DAY></DATE><COMMENT>This presentation of Anthropic‚Äôs analysis on how to improve RAG is poorly done.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Multimodal Document RAG with Llama 3.2 Vision and ColQwen2</T><A>https://www.together.ai/blog/multimodal-document-rag-with-llama-3-2-vision-and-colqwen2</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Zain</FIRSTNAME><LASTNAME>Hasan</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>8</DAY></DATE><COMMENT>A presentation of ColPali design: using a vision language model (PaliGemma or Qwen-2) to transform image patches into vectors, finding the patch vectors nearest to the user query, and providing the corresponding full images and user query to a vision LLM (Llama 3.2 vision).</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Docling</T><A>https://simonwillison.net/2024/Nov/3/docling/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>3</DAY></DATE><COMMENT>A short feeedback on experimenting with <CODEROUTINE>docling</CODEROUTINE>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Why Your RAG System Is Broken, and How to Fix It with Jason Liu</T><A>https://twimlai.com/podcast/twimlai/why-your-rag-pipeline-is-broken-and-how-to-fix-it/</A><L>en</L><F>MP3</F><DURATION><MINUTE>55</MINUTE><SECOND>33</SECOND></DURATION></X><X><T>Why Your RAG System Is Broken, and How to Fix It with Jason Liu - 709</T><A>https://www.youtube.com/watch?v=wexpoR1R03A</A><L>en</L><F>MP4</F><DURATION><MINUTE>57</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Liu</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Charrington</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>11</DAY></DATE><COMMENT>Some advice on RAG implementation: doing fast and simple evals (e.g. looking at the length, using regexp‚Ä¶), use them very frequently, reranking‚Ä¶</COMMENT></ARTICLE></ITEM>
      <ITEM><BLIST><TITLE>NotebookLM</TITLE>
        <ITEM><ARTICLE><X><T>Google's RAG Experiment - NotebookLM</T><A>https://www.youtube.com/watch?v=nK61ZpAS13s</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>38</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>28</DAY></DATE><COMMENT>The title says it all. Google demo is impressive, using voice for querying and answering.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Sorry Lex, Google AI's making podcasts now!!! üí• Create your own podcast with NotebookLM AI üí•</T><A>https://www.youtube.com/watch?v=qhmu5DP8Rmg</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>20</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>A presentation of an impressive Google demo usable (from Illuminate and NotebookLM): you give a paper as entry, it generates a two-persons podcast.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>NotebookLM‚Äôs automatically generated podcasts are surprisingly effective</T><A>https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>29</DAY></DATE><COMMENT>People are playing with NotebookLM-generated podcasts, sometimes at a meta-level.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>New in NotebookLM: Customizing your Audio Overviews</T><A>https://simonwillison.net/2024/Oct/17/notebooklm-pelicans/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>17</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR> is playing with the fact that NotebookLM users can now provide guidelines for the podcast to generate: as usual he picks up the pelican example and asks the AI-hosts to behave as if they were pelicans.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Google's UNREAL AI Gets an UPGRADE...</T><A>https://www.youtube.com/watch?v=oSuXs0w1PPY</A><L>en</L><F>MP4</F><DURATION><MINUTE>34</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Wes</FIRSTNAME><LASTNAME>Roth</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>19</DAY></DATE><COMMENT>The "poop fart" podcast and how <AUTHOR><FIRSTNAME>Wes</FIRSTNAME><LASTNAME>Roth</LASTNAME></AUTHOR> added video on it using HeyGen. He also quickly describes the new NotebookLM features.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Web scrapping</TITLE>
      <ITEM><ARTICLE><X><T>Web Scraping AI AGENT, that absolutely works üòç</T><A>https://www.youtube.com/watch?v=zDqAZOiPX_M</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>9</DAY></DATE><COMMENT>A presentation of <X><T>ScrapeGraphAI</T><A>https://pypi.org/project/scrapegraphai/</A><L>en</L><F>HTML</F></X>, a Python library to scrap a Web site and to interrogate an LLM on the scrapped data.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>‚ÄúWait, this Agent can Scrape ANYTHING?!‚Äù - Build universal web scraping agent</T><A>https://www.youtube.com/watch?v=dSX5eoD4-u4</A><L>en</L><F>MP4</F><DURATION><MINUTE>29</MINUTE><SECOND>10</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>16</DAY></DATE><COMMENT>Scrapping the Web with <X><T>FireCrawl</T><A>https://www.firecrawl.dev/</A><L>en</L><F>HTML</F></X> or <X><T>AgentQL</T><A>https://www.agentql.com/</A><L>en</L><F>HTML</F></X>, and an LLM.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>How to scrape the web for LLM in 2024: Jina AI (Reader API), Mendable (firecrawl) and Scrapegraph-ai</T><A>https://www.youtube.com/watch?v=QxHE4af5BQE</A><L>en</L><F>MP4</F><DURATION><MINUTE>20</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Hai</FIRSTNAME><LASTNAME>Nghiem</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>17</DAY></DATE><COMMENT>Some Web scrapping tools: Beautiful Soup, Jina AI, Firecrawl, and Scrapegraph-ai.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>How Stack Overflow fends off scraping bots</T><ST>Josh Zhang, a staff site reliability engineer at Stack Overflow, tells Ryan and Eira how the Stack Exchange network defends against scraping bots. They also cover the emergence of human botnets, why DDoS attacks have spiked in the last couple of years, and the constant balancing act of protecting sites from attack without inhibiting legitimate users.</ST><A>https://stackoverflow.blog/2024/07/30/how-stack-overflow-fends-off-scraping-bots/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Josh</FIRSTNAME><LASTNAME>Zhang</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Ryan</FIRSTNAME><LASTNAME>Donovan</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Eira</FIRSTNAME><LASTNAME>May</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>30</DAY></DATE><COMMENT>The subtitle says it all.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Agentically scrape the web with Firecrawl &amp; LangGraph (LangChain)</T><A>https://www.youtube.com/watch?v=vSz5-KeRyHs</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>44</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Hai</FIRSTNAME><LASTNAME>Nghiem</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>25</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>NuExtract 1.5</T><A>https://simonwillison.net/2024/Nov/16/nuextract-15/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>16</DAY></DATE><COMMENT>NuExtract models extract structured data from unstructured text.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Tool calling</TITLE>
      <ITEM><ARTICLE><X><T>AI Agents' Secret Sauce</T><A>https://www.youtube.com/watch?v=MRYqhbtLTmM</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>7</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>7</DAY></DATE><COMMENT>Some basic but good advice on how to implement tools.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Frameworks</TITLE>
      <ITEM><ARTICLE><X><T>LLM Toolkit: Validation is all you need</T><A>https://www.mechanical-orchard.com/insights/llm-toolkit-validation-is-all-you-need</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Jeff</FIRSTNAME><LASTNAME>Schomay</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>20</DAY></DATE><COMMENT>Building a tool that, from an English question, performs a database request and generates an answer, using Instructor and Fructose.</COMMENT></ARTICLE></ITEM>
      <ITEM><BLIST><TITLE>LangChain</TITLE>
        <ITEM><ARTICLE><X><T>LangChain101: Question A 300 Page Book (w/ OpenAI + Pinecone)</T><A>https://www.youtube.com/watch?v=h0DHDp1FbmQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>2</MONTH><DAY>27</DAY></DATE><COMMENT>A small demo using LangChain, OpenAI, and Pinecone.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Workaround OpenAI's Token Limit With Chain Types</T><A>https://www.youtube.com/watch?v=f9_BWhCI4Zo</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>51</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>3</MONTH><DAY>1</DAY></DATE><COMMENT>Some solutions to summarise or extract answers from too long documents.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>The LangChain Cookbook - Beginner Guide To 7 Essential Concepts</T><A>https://www.youtube.com/watch?v=2xxziIWmaSA</A><L>en</L><F>MP4</F><DURATION><MINUTE>38</MINUTE><SECOND>10</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>3</MONTH><DAY>29</DAY></DATE><COMMENT>Some short examples of the LangChain features.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE predecessor="https://www.youtube.com/watch?v=2xxziIWmaSA"><X><T>The LangChain Cookbook Part 2 - Beginner Guide To 9 Use Cases</T><A>https://www.youtube.com/watch?v=vGP4pQdCocw</A><L>en</L><F>MP4</F><DURATION><MINUTE>26</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>5</MONTH><DAY>2</DAY></DATE><COMMENT>The continuation of the previous video.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>LangChain: Run Language Models Locally - Hugging Face Models</T><A>https://www.youtube.com/watch?v=Xxxuw4_iCzw</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>4</MONTH><DAY>25</DAY></DATE><COMMENT>A demo of executing a model on Hugging Face and locally.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>5 Levels Of LLM Summarizing: Novice to Expert</T><A>https://www.youtube.com/watch?v=qaPMdcCqtWk&amp;pp=gAQBiAQB</A><L>en</L><F>MP4</F><DURATION><MINUTE>19</MINUTE><SECOND>18</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Greg</FIRSTNAME><LASTNAME>Kamradt</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>5</MONTH><DAY>4</DAY></DATE><COMMENT>More LangChain examples.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Scrape any website with OpenAI Functions &amp; LangChain</T><A>https://www.youtube.com/watch?v=0gPh18vRghQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>24</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><GIVENNAME>LLM School</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>8</MONTH><DAY>2</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Construire son RAG (Retrieval Augmented Generation) gr√¢ce √† langchain: L‚Äôexemple de l‚ÄôHelpdesk d‚ÄôOCTO</T><A>https://blog.octo.com/le-chatbot-docto-langchain-rag-et-code-associe</A><L>fr</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Florian</FIRSTNAME><LASTNAME>Bastin</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Nicolas</FIRSTNAME><LASTNAME>Cavallo</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>17</DAY></DATE><COMMENT>A detailed example demonstrating how to extract data from Confluence, embed the chunks, create a chain to find and format the answer, and evaluate the result.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Gradio 5 - Building a Quick Chabot UI for LangChain</T><A>https://www.youtube.com/watch?v=u_Xm3vgBQ9Y</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>10</DAY></DATE><COMMENT>A small example of a streaming chat program with Gradio 5 and LangChain.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>LangChain4J</TITLE>
        <ITEM><ARTICLE><X><T>Java Meets AI: A Hands On Guide to Building LLM Powered Applications with LangChain4j By Lize Raes</T><A>https://www.youtube.com/watch?v=BD1MSLbs9KE</A><L>en</L><F>MP4</F><DURATION><MINUTE>50</MINUTE><SECOND>47</SECOND></DURATION></X><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>5</DAY></DATE><COMMENT>An overview of LangChain4j.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Experiments with Langchain4j or Java way to LLM-powered applications</T><A>https://kindgeek.com/blog/post/experiments-with-langchain4j-or-java-way-to-llm-powered-applications</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Iryna</FIRSTNAME><LASTNAME>Hvozdyk</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>6</DAY></DATE><COMMENT>A good overview of LangChain4j features, this is mostly for persons who do not know the typical AI use cases.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>The Definitive Guide to Tool Support in LangChain4J</T><A>https://www.youtube.com/watch?v=cjI_6Siry-s</A><L>en</L><F>MP4</F><DURATION><MINUTE>28</MINUTE><SECOND>19</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Ken</FIRSTNAME><LASTNAME>Kousen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>24</DAY></DATE><COMMENT>A rather slow presentation of using tools in LangChain4j.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Java rencontre l'IA : Comment int√©grer les LLMs dans vos applications avec LangChain4j</T><A>https://www.youtube.com/watch?v=0FEUmI2Ou10</A><L>fr</L><F>MP4</F><DURATION><MINUTE>46</MINUTE><SECOND>34</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Lize</FIRSTNAME><LASTNAME>Raes</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>3</DAY></DATE><COMMENT>The same, in French and updated.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Tools</TITLE>
      <ITEM><BLIST><TITLE>Ollama</TITLE>
        <ITEM><ARTICLE><X><T>Ollama on CPU and Private AI models!</T><A>https://www.youtube.com/watch?v=C0GmAmyhVxM</A><L>en</L><F>MP4</F><DURATION><MINUTE>23</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>8</DAY></DATE><COMMENT>A presentation of Ollama.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Ollama Web UI (ChatGPT-ish) - Local AI FTW!!!</T><A>https://www.youtube.com/watch?v=wxvFr4T7irs</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>1</DAY></DATE><COMMENT>Running Ollama Web UI in Docker.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Fine Tune a model with MLX for Ollama</T><A>https://www.youtube.com/watch?v=3UQ7GY9hNwk</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>30</DAY></DATE><COMMENT>How to fine-tune a model with MLX and use it in Ollama.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Ollama's Newest Release and Model Breakdown</T><A>https://www.youtube.com/watch?v=ytUr9IX1cIA</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>59</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>21</DAY></DATE><COMMENT>Ollama 0.3.11, Solar Pro Preview, Qwen 2.5, Bespoke Minicheck, Mistral Small, and Reader-LM.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X quality="-1"><T>Quick Look at Hollama</T><A>https://www.youtube.com/watch?v=gKM3Y4tUF_s</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>35</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>8</DAY></DATE><COMMENT>The "unboxing" of Hollama, a good basic UI for Ollama. But there is little value in such a video, you can easily do the same yourself.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Ollama + HuggingFace - 45,000 New Models</T><A>https://www.youtube.com/watch?v=eLfJqWwdb6o</A><L>en</L><F>MP4</F><DURATION><MINUTE>7</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>25</DAY></DATE><COMMENT>Ollama can now use any GGUF recorded on Hugging Face.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Ollama: Llama 3.2 Vision</T><A>https://simonwillison.net/2024/Nov/13/ollama-llama-vision/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>13</DAY></DATE><COMMENT>Some very little information about Ollama supporting the vision features of Llama 3.2.</COMMENT></ARTICLE></ITEM>
        <ITEM><BLIST><TITLE>The Ollama Course of <AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR></TITLE>
          <ITEM><ARTICLE><X><T>The Ollama Course: Intro to Ollama</T><A>https://www.youtube.com/watch?v=2Pm93agyxx4</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>38</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>23</DAY></DATE><COMMENT>An overview od Ollama: installation, basic usage, and downloading a model.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Installing Ollama - #2 of the Free Ollama Course</T><A>https://www.youtube.com/watch?v=e3j1a2PKw1k</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>11</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>30</DAY></DATE><COMMENT>How to install Ollama on Windows, Linux, and MacOS.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Ollama Course - 3 - How to use the Ollama.com site to Find Models</T><A>https://www.youtube.com/watch?v=_fQTOMdqjfY</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>6</DAY></DATE><COMMENT>An explanation of the description of Ollama models.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>The Ollama Course - Using the CLI</T><A>https://www.youtube.com/watch?v=luH9j_eOEi4</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>8</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>14</DAY></DATE><COMMENT>A presentation of all the CLI commands.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Comparing Quantizations of the Same Model - Ollama Course</T><A>https://www.youtube.com/watch?v=8r9Kit3lKXE</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>28</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>21</DAY></DATE><COMMENT>Compare the results of the same model with different quantisations and select the one that has the quality / speed that is the best for your needs.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>An Introduction to RAG - Part of the Free Ollama Course</T><A>https://www.youtube.com/watch?v=1XCEZW_Twr0</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>5</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>29</DAY></DATE><COMMENT>A basic introduction to RAG.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Embeddings in Depth - Part of the Ollama Course</T><A>https://www.youtube.com/watch?v=aGwb1KLmtog</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>26</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>4</DAY></DATE><COMMENT>An overview on how to perform embedding using Olllama.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Let's build a RAG system - The Ollama Course</T><A>https://www.youtube.com/watch?v=FQTCLOUnIzI</A><L>en</L><F>MP4</F><DURATION><MINUTE>7</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>11</DAY></DATE><COMMENT>An example of a small RAG program, both in Python and JavaScript.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>What are the different types of models - The Ollama Course</T><A>https://www.youtube.com/watch?v=f4tXwCNP1Ac</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>19</DAY></DATE><COMMENT>A basic presentation of the model types: text/base, chat/instruct, code, and vision.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Crack Ollama Environment Variables with Ease - Part of the Ollama Course</T><A>https://www.youtube.com/watch?v=VKlcZCc5uQQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>6</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>26</DAY></DATE><COMMENT>The most important environment variables and how to set them on MacOS, Linux, and Windows.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Upgrade Your AI Using Web Search - The Ollama Course</T><A>https://www.youtube.com/watch?v=GMlSFIp1na0</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>2</DAY></DATE><COMMENT>A simple program using SearNGX and Cheerio to perform a Web search, retrieve the found pages, scrap the text in them, and generate an answer with Llama 3.2 1B.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X status="zombie"><T>Taming AI Hallucinations?</T><A>https://www.youtube.com/watch?v=c9QtACufYJM</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>9</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR> describes some basic facts about hallucination.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Unlock AI Mastery with Pro Tips on Prompting!</T><A>https://www.youtube.com/watch?v=QMHfa5WSbro</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>35</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>16</DAY></DATE><COMMENT>Some basics on prompt writing.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Master Ollama's File Layout in Minutes!</T><A>https://www.youtube.com/watch?v=aHhQvxwkuuw</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>42</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>23</DAY></DATE><COMMENT>A description of how Ollama records the models using several files, similarly to what Docker does.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Don‚Äôt Embed Wrong!</T><A>https://www.youtube.com/watch?v=76EIC_RaDNw</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>41</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>31</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR> speaks about using prefixes for RAG with Ollama, but there is no explanation of how they work, he just says that they improve results.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>AI Model Context Decoded</T><A>https://www.youtube.com/watch?v=-Lyk7ygQw2E</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>20</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>6</DAY></DATE><COMMENT>How to change the context size and some warnings about using a large context size.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>AI Vision Models Take a Peek Again!</T><A>https://www.youtube.com/watch?v=DNNOo-742OQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>26</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>8</DAY></DATE><COMMENT>Using Llama 3.2‚Äôs vision in Ollama 0.4.0.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Let's Update Ollama Everywhere</T><A>https://www.youtube.com/watch?v=DgMzvCFN0zQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>13</DAY></DATE><COMMENT>Explaining something very basic: upgrading Ollama on Mac, Windows, Linux, and Docker.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Cracking the Enigma of Ollama Templates</T><A>https://www.youtube.com/watch?v=anEdBxXtLs4</A><L>en</L><F>MP4</F><DURATION><MINUTE>7</MINUTE><SECOND>38</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>20</DAY></DATE><COMMENT>An introduction to model templates.</COMMENT></ARTICLE></ITEM>
          <ITEM><ARTICLE><X><T>Find Your Perfect Ollama Build</T><A>https://www.youtube.com/watch?v=RFaMiQ97EoE</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>22</DAY></DATE><COMMENT>How to build Ollama, the <CODEROUTINE>main</CODEROUTINE> branch or a PR.</COMMENT></ARTICLE></ITEM>
        </BLIST></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>llm</TITLE>
        <ITEM><ARTICLE><X><T>Language models on the command-line w/ Simon Willison</T><A>https://www.youtube.com/watch?v=QUXQNi6jQ30</A><L>en</L><F>MP4</F><DURATION><HOUR>1</HOUR><MINUTE>7</MINUTE><SECOND>4</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Hugo</FIRSTNAME><LASTNAME>Bowne-Anderson</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>13</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR> presents his <CODEROUTINE>llm</CODEROUTINE> CLI tools.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE predecessor="https://www.youtube.com/watch?v=QUXQNi6jQ30"><X><T>Language models on the command-line</T><A>https://simonwillison.net/2024/Jun/17/cli-language-models/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>17</DAY></DATE><COMMENT>An overview of the video.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Using LLMs on the command line</T><A>https://www.youtube.com/watch?v=aQuuJuCa0VM</A><L>en</L><F>MP4</F><DURATION><MINUTE>4</MINUTE><SECOND>11</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Mark</FIRSTNAME><LASTNAME>Needham</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>26</DAY></DATE><COMMENT>A short presentation of <CODEROUTINE>llm</CODEROUTINE>.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Agents</TITLE>
      <ITEM><ARTICLE><X><T>5 Problems Getting LLM Agents into Production</T><A>https://www.youtube.com/watch?v=06kslWw_QOc</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>11</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>4</DAY></DATE><COMMENT>Some advice on using agents.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Evals for AI Agents, the right way!!!</T><A>https://www.youtube.com/watch?v=ogc4vEkpLL0</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>12</DAY></DATE><COMMENT>The usual bad presentation of a paper ("<X><T>TOOLSANDBOX: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities</T><A>https://arxiv.org/abs/2408.04682</A><L>en</L><F>HTML</F></X>") evaluating the efficiency of using LLM as agents.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Agent-S : Unleash The Power Of GUI Computer Use Agents !</T><A>https://www.youtube.com/watch?v=q8SgHYV2zUk</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>59</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>21</DAY></DATE><COMMENT>A high level presentation of "<X><T>Agent S: An Open Agentic Framework that Uses Computers Like a Human</T><A>https://arxiv.org/abs/2410.08164</A><L>en</L><F>HTML</F></X>: an framework to use applications as a human would do it.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Browser Use Agent: This FULLY FREE AI Agent CAN CONTROL BROWSERS &amp; DO ANYTHING! (Beats Anthropic!)</T><A>https://www.youtube.com/watch?v=h6ibW12gWgs</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT>A presentation of <X><T>Browser Use</T><A>https://github.com/gregpr07/browser-use</A><L>en</L><F>HTML</F></X>, a Python framework to create agents ablet to drive a Browser.</COMMENT></ARTICLE></ITEM>
      <ITEM><BLIST><TITLE>LangGraph</TITLE>
        <ITEM><ARTICLE><X><T>AgentWrite with LangGraph</T><A>https://www.youtube.com/watch?v=nK9K8UPraXk</A><L>en</L><F>MP4</F><DURATION><MINUTE>19</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>6</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> describes how he set up a short LangGraph example to write long articles, similarly to LongWriter.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Building a LangGraph ReAct Mini Agent</T><A>https://www.youtube.com/watch?v=pEMhPBQMNjg</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>46</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>A description of a simple Pattern in LangGraph: ReAct Function Calling.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>ChatDev</TITLE>
        <ITEM><ARTICLE><X><T>Build AI agent workforce - Multi agent framework with MetaGPT &amp; chatDev</T><A>https://www.youtube.com/watch?v=pJwR5pv0_gs</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>40</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>9</MONTH><DAY>8</DAY></DATE><COMMENT>A presentation of <X><T>ChatDev</T><A>https://chatdev.ai/</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>CrewAI</TITLE>
        <ITEM><ARTICLE><X><T>CrewAI August Update: Planning Steps, Training, and Advanced Features Explained</T><A>https://www.youtube.com/watch?v=uGj4REGFp3A</A><L>en</L><F>MP4</F><DURATION><MINUTE>22</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>20</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> presents some new CrewAI features, but there is no explanation on how training is taken into account, on how test scores are computed‚Ä¶</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Autogen</TITLE>
        <ITEM><ARTICLE><X><T>Autogen - Microsoft's best AI Agent framework that is controllable?</T><A>https://www.youtube.com/watch?v=Bq-0ClZttc8</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>49</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jason</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>3</DAY></DATE><COMMENT>A presentation of <X><T>AutoGen</T><A>https://microsoft.github.io/autogen/</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Microsoft's Magentic One: This FREE AI AGENT can CONTROL BROWSER, DO CODING &amp; MORE!</T><A>https://www.youtube.com/watch?v=w7MLNN8MH0o</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>10</DAY></DATE><COMMENT>A presentation and some little test of Magentic-One, a multi-agent system from Microsoft able to surf on the Web, read local file, write code, and pilot a terminal to execute that code.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Multi-Agent AI EXPLAINED: How Magentic-One Works</T><A>https://www.youtube.com/watch?v=RUDZZLtB08w</A><L>en</L><F>MP4</F><DURATION><MINUTE>16</MINUTE><SECOND>38</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>13</DAY></DATE><COMMENT>A better presentation of Magentic-One.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
      <ITEM><BLIST><TITLE>Swarm</TITLE>
        <ITEM><ARTICLE><X><T>Introducing Swarm with Code Examples: OpenAI's Groundbreaking Agent Framework</T><A>https://www.youtube.com/watch?v=npAljHBeKPc</A><L>en</L><F>MP4</F><DURATION><MINUTE>27</MINUTE><SECOND>53</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>14</DAY></DATE><COMMENT>Some simple examples using Swarm framework and some feedback about it.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
  </BLIST></ITEM>
</LLIST>
</CONTENT>
</PAGE>