<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="../css/strict.xsl"?>
<PAGE xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../css/schema.xsd" xml:lang="en">
<TITLE>AI models</TITLE>
<PATH>links/aimodels.xml</PATH>
<DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>26</DAY></DATE>
<CONTENT>
<LLIST>
  <ITEM><BLIST><TITLE>Articles and videos</TITLE>
    <ITEM><ARTICLE><X quality="1"><T>Uncensored Models</T><A>https://erichartford.com/uncensored-models</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Eric</FIRSTNAME><LASTNAME>Hartford</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>5</MONTH><DAY>15</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Eric</FIRSTNAME><LASTNAME>Hartford</LASTNAME></AUTHOR> explains how and why he fine-tunes some uncensored models.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>NEW "Orca-2" üê≥ Official Release - 13B Better than 70B Models</T><A>https://www.youtube.com/watch?v=ofJLbfyYOms</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>8</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>23</DAY></DATE><COMMENT>The title says it all (<X><T>microsoft/Orca-2-13b</T><A>https://huggingface.co/microsoft/Orca-2-13b</A><L>en</L><F>HTML</F></X>).</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Intel‚Äôs Neural Chat is Top-Ranked 7B Chat Model on the Leaderboard | Train models on CPUs</T><A>https://www.youtube.com/watch?v=EO0-dzPTa6A</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineer</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>25</DAY></DATE><COMMENT>A minimalist presentation of <X><T>Intel/neural-chat-7b-v3</T><A>https://huggingface.co/Intel/neural-chat-7b-v3</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Neural-Chat 7B: New Best 7B LLM from Intel</T><A>https://www.youtube.com/watch?v=fKx_7S0SzDA</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>20</SECOND></DURATION></X><AUTHOR><GIVENNAME>Prompt Engineering</GIVENNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>27</DAY></DATE><COMMENT>An evaluation of <X><T>Intel/neural-chat-7b-v3</T><A>https://huggingface.co/Intel/neural-chat-7b-v3</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Should You Use Open Source Large Language Models?</T><A>https://www.youtube.com/watch?v=y9k-U9AuDeM</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Martin</FIRSTNAME><LASTNAME>Keen</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>27</DAY></DATE><COMMENT>A basic presentation of the LLM landscape.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Small LLM, Good Model, Bad License!!!</T><A>https://www.youtube.com/watch?v=THzmh7rvW2k</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>A basic presentation of <X><T>stabilityai/stablelm-zephyr-3b</T><A>https://huggingface.co/stabilityai/stablelm-zephyr-3b</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Mamba STRIKES again!!!</T><A>https://www.youtube.com/watch?v=LZw_mtcNlx8</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>14</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>18</DAY></DATE><COMMENT>A presentation of <X><T>state-spaces/mamba-2.8b-slimpj</T><A>https://huggingface.co/state-spaces/mamba-2.8b-slimpj</A><L>en</L><F>HTML</F></X>, a model not based on transformers.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Trust me, It's Open AI!</T><A>https://www.youtube.com/watch?v=0XQGAkCkbAI</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>19</DAY></DATE><COMMENT>A basic presentation of OpenChat 3.5.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>This Tiny Model is better than Phi 2 (somewhat!!!)</T><A>https://www.youtube.com/watch?v=dy963Nkpchs</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>46</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>21</DAY></DATE><COMMENT>A presentation of <X><T>stabilityai/stablelm-2-zephyr-1_6</T><A>https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Mambaaaa Again!!! (Mamba Hermes Tutorial)</T><A>https://www.youtube.com/watch?v=GDhcKNIuKP4</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>24</DAY></DATE><COMMENT>The usual quick ‚Äôn dirty model presentation, this time it is <X><T>clibrain/mamba-2.8b-instruct-openhermes</T><A>https://huggingface.co/clibrain/mamba-2.8b-instruct-openhermes</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>The EASIEST Local LLM App (OpenAI-compatible API)!!!</T><A>https://www.youtube.com/watch?v=hX8pt_drIck</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>42</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>28</DAY></DATE><COMMENT>A presentation of Jan, yet another tool to run chat models locally.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>RNN just outperformed TRANSFORMERS!!!</T><A>https://www.youtube.com/watch?v=gHdRgfmAVIw</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>48</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>29</DAY></DATE><COMMENT>A presentation of <X><T>RWKV/v5-Eagle-7B</T><A>https://huggingface.co/RWKV/v5-Eagle-7B-pth</A><L>en</L><F>HTML</F></X>, a RWKV model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Very small vision language model!!! (MoonDream V1)</T><A>https://www.youtube.com/watch?v=1b9erAtYr9A</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>29</DAY></DATE><COMMENT>A quick ‚Äôn dirty presentation of <X><T>vikhyatk/moondream1</T><A>https://huggingface.co/vikhyatk/moondream1</A><L>en</L><F>HTML</F></X>, a small vision language model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>This VLM can be your MultiModal AI with less than 6GB Memory!!!</T><A>https://www.youtube.com/watch?v=_BzWviKLtxg</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>49</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>5</DAY></DATE><COMMENT>A demonstration of moondream2, a small vision model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>The RAG King üëë goes HUGE!!!</T><A>https://www.youtube.com/watch?v=Knjc25bPn3w</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>39</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>4</DAY></DATE><COMMENT><X><T>CohereForAI/c4ai-command-r-plus</T><A>https://huggingface.co/CohereLabs/c4ai-command-r-plus</A><L>en</L><F>HTML</F></X></COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Apple releases eight small AI language models aimed at on-device use</T><ST>OpenELM mirrors efforts by Microsoft to make useful small AI language models that run locally.</ST><A>https://arstechnica.com/information-technology/2024/04/apple-releases-eight-small-ai-language-models-aimed-at-on-device-use/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>25</DAY></DATE><COMMENT>The title says it all.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>MASSIVE Leap for LLama3! OpenChat's 3.6 8B Model Obliterates LLama3 8B!</T><A>https://www.youtube.com/watch?v=-j4CQS6dGtc</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>27</DAY></DATE><COMMENT>A botched evaluation of <X><T>openchat/openchat-3.6-8b</T><A>https://huggingface.co/openchat/openchat-3.6-8b-20240522</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>ChatTTS -  Conversational TTS Step by Step</T><A>https://www.youtube.com/watch?v=L4klnZ5Lox8</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>13</DAY></DATE><COMMENT>A presentation of ChatTTS, a text to speech model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Nemotron-4 340B - Need to Make a LLM Dataset?</T><A>https://www.youtube.com/watch?v=Pk0VzEwjYos</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>12</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>16</DAY></DATE><COMMENT>A presentation of the Nemotron models which are usable to generate synthetic data.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Introducing The New Champion of Function Calling!</T><A>https://www.youtube.com/watch?v=A2YnVQ1T3Lg</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>18</DAY></DATE><COMMENT>A presentation of <X><T>Groq/Llama-3-Groq-8B-Tool-Use</T><A>https://huggingface.co/Groq/Llama-3-Groq-8B-Tool-Use</A><L>en</L><F>HTML</F></X> and <X><T>Groq/Llama-3-Groq-70B-Tool-Use</T><A>https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use</A><L>en</L><F>HTML</F></X>, models based on Llama 3 specialised for function calling.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Best Open Source Text-to-Speech AI Tutorial in 2024</T><A>https://www.youtube.com/watch?v=STuEJLBLvoc</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>44</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>18</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR> demoes Parler-TTS.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>The Ultimate Writing Challenge: Longwriter Tackles 10,000 Words In One Sitting</T><A>https://www.youtube.com/watch?v=6cubCIupyik</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>30</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> presents <X><T>THUDM/LongWriter-glm4-9b</T><A>https://huggingface.co/zai-org/LongWriter-glm4-9b</A><L>en</L><F>HTML</F></X> and <X><T>THUDM/LongWriter-llama3.1-8b</T><A>https://huggingface.co/zai-org/LongWriter-llama3.1-8b</A><L>en</L><F>HTML</F></X>, two models fine-tuned for generating long output.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Open Reasoning vs OpenAI</T><A>https://www.youtube.com/watch?v=vN8jBxEKkVo</A><L>en</L><F>MP4</F><DURATION><MINUTE>26</MINUTE><SECOND>58</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>29</DAY></DATE><COMMENT>Some information and experimentation with DeepSeek R1, Qwen QwQ, and Marco-01.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Automated Reasoning to Prevent LLM Hallucination with Byron Cook</T><A>https://twimlai.com/podcast/twimlai/automated-reasoning-to-prevent-llm-hallucination/</A><L>en</L><F>MP3</F><DURATION><MINUTE>57</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Byron</FIRSTNAME><LASTNAME>Cook</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Charrington</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>9</DAY></DATE><COMMENT>Amazon Bedrock Guardrails now offers Automated Reasoning checks, these are controlled by a proof engine. <AUTHOR><FIRSTNAME>Byron</FIRSTNAME><LASTNAME>Cook</LASTNAME></AUTHOR> also speaks about his past experience on solvers and proof verifiers.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Exaone3.5 Performance in #ollama</T><A>https://www.youtube.com/watch?v=Y6Ehvbm5GRI</A><L>en</L><F>MP4</F><DURATION><MINUTE>23</MINUTE><SECOND>1</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>19</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR> received a powerful server on loan, but he does a poor job of evaluating different versions of <X><T>EXAONE 3.5</T><A>https://huggingface.co/collections/LGAI-EXAONE/exaone-35-674d0e1bb3dcd2ab6f39dbb4</A><L>en</L><F>HTML</F></X> on it.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Rubik's Sonus 1: This FULLY FREE Reasoning Model is ABSOLUTELY INSANE!</T><A>https://www.youtube.com/watch?v=StQ3xe2InpE</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>7</DAY></DATE><COMMENT>Yet another quick ‚Äôn dirty benchmark. Other sources indicate that Sonus is in fact just Llama 3 rebranded.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>SmolDocling - The SmolOCR Solution?</T><A>https://www.youtube.com/watch?v=kPKRJeLMq_M</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>16</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>18</DAY></DATE><COMMENT>The usual <AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR>‚Äôs announcement reading: <X><T>ds4sd/SmolDocling-256M-preview</T><A>https://huggingface.co/ds4sd/SmolDocling-256M-preview</A><L>en</L><F>HTML</F></X> is a small model for extracting structured data from documents.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Shisa V2 405B: Japan‚Äôs Highest Performing LLM</T><A>https://simonwillison.net/2025/Jun/3/shisa-v2/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>6</MONTH><DAY>3</DAY></DATE><COMMENT>Japan released a model based on Llama 3.1 405B tuned for CJK.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>The last six months in LLMs, illustrated by pelicans on bicycles</T><A>https://simonwillison.net/2025/Jun/6/six-months-in-llms/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>6</MONTH><DAY>6</DAY></DATE><COMMENT>The noticeable models and buzzes of the last six months.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Comma v0.1 1T and 2T‚Äî7B LLMs trained on openly licensed text</T><A>https://simonwillison.net/2025/Jun/7/comma/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>6</MONTH><DAY>7</DAY></DATE><COMMENT>A small model trained on text openly licensed or in the public domain.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Small vs. Large AI Models: Trade-offs &amp; Use Cases Explained</T><A>https://www.youtube.com/watch?v=0Wwn5IEqFcg</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Martin</FIRSTNAME><LASTNAME>Keen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>6</MONTH><DAY>10</DAY></DATE><COMMENT>Some basics about the fact that smaller models are catching up the quality level of previous larger models, and that the choice between a small or a large model depends on what you want to do with it.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>model.yaml</T><A>https://simonwillison.net/2025/Jun/21/model-yaml/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>6</MONTH><DAY>21</DAY></DATE><COMMENT>LM Studio proposes a YAML schema to define the characteristics of a model.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>XBai o4</T><A>https://simonwillison.net/2025/Aug/3/xbai-o4/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>8</MONTH><DAY>3</DAY></DATE><COMMENT>Yet another open-weights model from China.</COMMENT></ARTICLE></ITEM>
    <ITEM><BLIST><TITLE>Phi</TITLE>
      <ITEM><ARTICLE><X><T>Microsoft‚Äôs Phi-3 shows the surprising power of small, locally run AI language models</T><ST>Microsoft‚Äôs 3.8B parameter Phi-3 may rival GPT-3.5, signaling a new era of ‚Äúsmall language models."</ST><A>https://arstechnica.com/information-technology/2024/04/microsofts-phi-3-shows-the-surprising-power-of-small-locally-run-ai-language-models/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>23</DAY></DATE><COMMENT>Some little information, mostly Microsoft‚Äôs PR, on Phi-3-mini.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Testing Microsoft's New VLM - Phi-3 Vision</T><A>https://www.youtube.com/watch?v=iz2rXDLyBHU</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>52</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>7</DAY></DATE><COMMENT>A presentation of a small test of Phi-3 Vision.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Microsoft's Phi 3.5 - The latest SLMs</T><A>https://www.youtube.com/watch?v=wVuwTeW4Ow4</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>21</DAY></DATE><COMMENT>A <AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR>‚Äôs classical presentation and short experimentation with the models.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Phi-4 Technical Report</T><A>https://simonwillison.net/2024/Dec/15/phi-4-technical-report/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>15</DAY></DATE><COMMENT>Some extracts from Microsoft Phi-4 announcement.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Microsoft Phi-4 (14B) : This Opensource LLM is a MINI BEAST! The Best 14B Model YET! (Beats Qwen!)</T><A>https://www.youtube.com/watch?v=w22WT1bgn5s</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>14</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>17</DAY></DATE><COMMENT><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR> is very satisfied by Phi 4.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Unlock Open Multimodality  with Phi-4</T><A>https://www.youtube.com/watch?v=qAgAQQ41P3A</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>4</DAY></DATE><COMMENT>A presentation of the Phi-4 models and playing with their vision and audio capabilities.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Phi-4 Reasoning - Microsoft Joins the Reasoning Race!!</T><A>https://www.youtube.com/watch?v=H9DQVWnvmao</A><L>en</L><F>MP4</F><DURATION><MINUTE>17</MINUTE><SECOND>27</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>5</MONTH><DAY>2</DAY></DATE><COMMENT>The usual announcement reading: Microsoft released three Phi-4 models with reasoning capabilities.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Saying ‚Äúhi‚Äù to Microsoft‚Äôs Phi-4-reasoning</T><A>https://simonwillison.net/2025/May/6/phi-4-reasoning/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>5</MONTH><DAY>6</DAY></DATE><COMMENT>Comparing Phi-4-reasoning‚Äôs logorrhoea and Qwen 3 8B 4 bits‚Äô short thinking.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Alibaba</TITLE>
      <ITEM><ARTICLE><X><T>Marco-O1 : This New OPENSOURCE Model BEATS O1 &amp; SONNET? (with FREE API)</T><A>https://www.youtube.com/watch?v=_8Uvu_Zely0</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>1</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>26</DAY></DATE><COMMENT>A presentation and quick ‚Äôn dirty evaluation of the model.</COMMENT></ARTICLE></ITEM>
      <ITEM><BLIST><TITLE>Qwen</TITLE>
        <ITEM><ARTICLE><X><T>China's RELENTLESS with new AI (Qwen 1.5) LLMs!!!</T><A>https://www.youtube.com/watch?v=THRJNJy90CQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>55</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>2</MONTH><DAY>5</DAY></DATE><COMMENT>Alibaba has released <X><T>many Qwen1.5 models</T><A>https://huggingface.co/collections/Qwen/qwen15-65c0a2f577b1ecb76d786524</A><L>en</L><F>HTML</F></X> of different sizes.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen 2 - For Reasoning or Creativity?</T><A>https://www.youtube.com/watch?v=UUylYfR4Kbs</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>45</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>10</DAY></DATE><COMMENT>A presentation and a dubious test of Qwen 2.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen QwQ-32B : This New OPENSOURCE Model BEATS O1 &amp; SONNET? (with FREE API)</T><A>https://www.youtube.com/watch?v=oX9ZMuKA2Ls</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>28</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>28</DAY></DATE><COMMENT>The usual basic presentation and evaluation for Qwen QwQ-32B.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Athene-V2 &amp; Agent : This NEW Opensource MODEL BEATS SONNET &amp; GPT-4O! (Best OPEN LLM w/ Free API)</T><A>https://www.youtube.com/watch?v=65J_ZKy3H3w</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>7</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>29</DAY></DATE><COMMENT>Always the same ad, presentation, and evaluation, this time for Athene-V2, a model fine-tuned from Qwen 2.5 72B.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Trying out QvQ‚ÄîQwen‚Äôs new visual reasoning model</T><A>https://simonwillison.net/2024/Dec/24/qvq/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>24</DAY></DATE><COMMENT>Some experimentation with the visual reasoning capabilities of QVQ-72B-Preview.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens</T><A>https://simonwillison.net/2025/Jan/26/qwen25-1m/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>26</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR> had trouble running Qwen2.5-7B-Instruct-1M locally, first because the context size was configured too small in Ollama, second because he did not have enough RAM.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen2.5 VL! Qwen2.5 VL! Qwen2.5 VL!</T><A>https://simonwillison.net/2025/Jan/27/qwen25-vl-qwen25-vl-qwen25-vl/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>27</DAY></DATE><COMMENT>A simple test of Qwen2.5 VL, the new vision model of Qwen.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Based on DeepSeek R1. Is it Better?</T><A>https://www.youtube.com/watch?v=5-IShq-wbas</A><L>en</L><F>MP4</F><DURATION><MINUTE>16</MINUTE><SECOND>5</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matt</FIRSTNAME><LASTNAME>Williams</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>22</DAY></DATE><COMMENT>Yet another quick ‚Äôn dirty evaluation. This time of openthinker, a fine-tuned Qwen2.5 using distillation from DeepSeek-R1.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>QwQ-32B (Fully Tested) : This NEW &amp; OPEN SMALL MODEL BEATS 3.7 Sonnet, R1 &amp; O3 Mini!?</T><A>https://www.youtube.com/watch?v=WgPrZ7FDYNI</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>16</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>6</DAY></DATE><COMMENT>The usual quick ‚Äôn dirty <AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR>‚Äôs evaluation.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen QwQ 32B - The Best Local Reasoning Model?</T><A>https://www.youtube.com/watch?v=oU0_vc1YT0k</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>6</DAY></DATE><COMMENT>The usual reading of the announcement, but, this time, there is no demo. I guess <AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR> rushed to publish something quickly.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen2.5-VL-32B: Smarter and Lighter</T><A>https://simonwillison.net/2025/Mar/24/qwen25-vl-32b/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>24</DAY></DATE><COMMENT>A very short article about the new model.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen 3 offers a case study in how to effectively release a model</T><A>https://simonwillison.net/2025/Apr/29/qwen-3/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>4</MONTH><DAY>29</DAY></DATE><COMMENT>Alibaba released eight variations of Qwen 3 and many tools were updated to support these as soon as the models have been delivered.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Introducing the Qwen 3 Family</T><A>https://www.youtube.com/watch?v=BkeDfyQmYR8</A><L>en</L><F>MP4</F><DURATION><MINUTE>16</MINUTE><SECOND>21</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>4</MONTH><DAY>29</DAY></DATE><COMMENT>The usual reading of the announcement and short demo.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>The 4 Things Qwen-3‚Äôs Chat Template Teaches Us</T><A>https://huggingface.co/blog/qwen-3-chat-template-deep-dive</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Caleb</FIRSTNAME><LASTNAME>Fahlgren</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>4</MONTH><DAY>30</DAY></DATE><COMMENT>A few details about Qwen3‚Äôs prompt.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-8B</T><A>https://simonwillison.net/2025/May/2/qwen3-8b/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>5</MONTH><DAY>2</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR>‚Äôs new favourite model is <X><T>mlx-community/Qwen3-8B-4bit</T><A>https://huggingface.co/mlx-community/Qwen3-8B-4bit</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>qwen2.5vl in Ollama</T><A>https://simonwillison.net/2025/May/18/qwen25vl-in-ollama/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>5</MONTH><DAY>18</DAY></DATE><COMMENT>A minimalist test of Qwen 2.5 VL.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen/Qwen3-235B-A22B-Instruct-2507</T><A>https://simonwillison.net/2025/Jul/22/qwen3-235b-a22b-instruct-2507/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>22</DAY></DATE><COMMENT>A new version of Qwen3, without reasoning.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-Coder: Agentic Coding in the World</T><A>https://simonwillison.net/2025/Jul/22/qwen3-coder/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>22</DAY></DATE><COMMENT>Yet another CLI agentic coding assistant.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-235B-A22B-Thinking-2507</T><A>https://simonwillison.net/2025/Jul/25/qwen3-235b-a22b-thinking-2507/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>25</DAY></DATE><COMMENT>Alibaba released the thinking version of the updated Qwen3.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-30B-A3B-Instruct-2507</T><A>https://simonwillison.net/2025/Jul/29/qwen3-30b-a3b-instruct-2507/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>29</DAY></DATE><COMMENT>An update of Qwen3 small model.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE predecessor="https://simonwillison.net/2025/Jul/29/qwen3-30b-a3b-instruct-2507/"><X><T>Qwen3-30B-A3B-Thinking-2507</T><A>https://simonwillison.net/2025/Jul/30/qwen3-30b-a3b-thinking-2507/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>30</DAY></DATE><COMMENT>The reasoning version of yesterday‚Äôs model.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen-Image: Crafting with Native Text Rendering</T><A>https://simonwillison.net/2025/Aug/4/qwen-image/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>8</MONTH><DAY>4</DAY></DATE><COMMENT>Yet another Qwen model, this one for image generation with a focus on text rendering.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-4B-Thinking: ‚ÄúThis is art‚Äîpelicans don‚Äôt ride bikes!‚Äù</T><A>https://simonwillison.net/2025/Aug/10/qwen3-4b/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>8</MONTH><DAY>10</DAY></DATE><COMMENT>Yet some new models, this time Qwen3-4B-Instruct-2507 and Qwen3-4B-Thinking-2507.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen-Image-Edit: Image Editing with Higher Quality and Efficiency</T><A>https://simonwillison.net/2025/Aug/19/qwen-image-edit/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>8</MONTH><DAY>19</DAY></DATE><COMMENT>Editing locally images using Qwen-Image.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-Next-80B-A3B: üêßü¶© Who needs legs?!</T><A>https://simonwillison.net/2025/Sep/12/qwen3-next/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>12</DAY></DATE><COMMENT>Some very little information about Qwen3-Next-80B-A3B-Instruct and Qwen3-Next-80B-A3B-Thinking.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3 Next - Behind the Curtain</T><A>https://www.youtube.com/watch?v=DfPKk-8fOGA</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>12</DAY></DATE><COMMENT>A presentation (i.e. reading of the announcement) and demo (i.e. simplistic examples) of these same models.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>Qwen3-VL: Sharper Vision, Deeper Thought, Broader Action</T><A>https://simonwillison.net/2025/Sep/23/qwen3-vl/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>23</DAY></DATE><COMMENT>The weights of Qwen3-VL-235B-A22B are now available.</COMMENT></ARTICLE></ITEM>
        <ITEM><ARTICLE><X><T>The Qwen Avalanche</T><A>https://www.youtube.com/watch?v=-_aurwwYeSc</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>57</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>24</DAY></DATE><COMMENT>A short presentation of the many new Qwen models.</COMMENT></ARTICLE></ITEM>
      </BLIST></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Moonshot</TITLE>
      <ITEM><ARTICLE><X><T>Kimi K2: Open Agentic Intelligence</T><A>https://moonshotai.github.io/Kimi-K2/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>11</DAY></DATE><COMMENT>Moonshot announces their new model: Kimi K2, a very large open-weights model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Kimi K2: Leading Open-Source Model Now Available on Together AI</T><A>https://www.together.ai/blog/kimi-k2-leading-open-source-model-now-available-on-together-ai</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>14</DAY></DATE><COMMENT>Together AI is offering Kimi K2.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Kimi K2: What‚Äôs all the fuss and what‚Äôs it like to use?</T><A>https://www.thoughtworks.com/insights/blog/generative-ai/kimi-k2-whats-fuss-whats-like-use</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Richard</FIRSTNAME><LASTNAME>Gall</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Zhenjia</FIRSTNAME><LASTNAME>Zhou</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>18</DAY></DATE><COMMENT>Some feedback on Kimi K2.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Kimi K2 0905 for Agents</T><A>https://www.youtube.com/watch?v=lglL34IPpYQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>55</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>5</DAY></DATE><COMMENT>A new version of Kimi K2, with the usual announcement reading and the short demo.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Kimi-K2-Instruct-0905</T><A>https://simonwillison.net/2025/Sep/6/kimi-k2-instruct-0905/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>6</DAY></DATE><COMMENT>Some very little information about the new model.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Hugging Face</TITLE>
      <ITEM><ARTICLE><X><T>Structured Generation w/ SmolLM2 running in browser &amp; WebGPU</T><A>https://simonwillison.net/2024/Nov/29/structured-generation-smollm2-webgpu/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>29</DAY></DATE><COMMENT>Running a 1.7B model (<X><T>HuggingFaceTB/SmolLM2-1.7B-Instruct</T><A>https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct</A><L>en</L><F>HTML</F></X>) in Chrome.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Using pip to install a Large Language Model that‚Äôs under 100MB</T><A>https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>7</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR> created a (useless) Pypi package embedding a tiny LLM (<X><T>HuggingFaceTB/SmolLM2-135M-Instruct</T><A>https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct</A><L>en</L><F>HTML</F></X>).</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="1"><T>SmolLM3: smol, multilingual, long-context reasoner</T><A>https://huggingface.co/blog/smollm3</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Elie</FIRSTNAME><LASTNAME>Bakouch</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Carlos</FIRSTNAME><MIDDLENAME>Miguel</MIDDLENAME><LASTNAME>Pati√±o</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Anton</FIRSTNAME><LASTNAME>Lozhkov</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Edward</FIRSTNAME><LASTNAME>Beeching</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Aymeric</FIRSTNAME><LASTNAME>Roucher</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Nouamane</FIRSTNAME><LASTNAME>Tazi</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Aksel</FIRSTNAME><MIDDLENAME>Joonas</MIDDLENAME><LASTNAME>Reedi</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Guilherme</FIRSTNAME><LASTNAME>Penedo</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Hynek</FIRSTNAME><LASTNAME>Kydlicek</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Cl√©mentine</FIRSTNAME><LASTNAME>Fourrier</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Nathan</FIRSTNAME><LASTNAME>Habib</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Kashif</FIRSTNAME><LASTNAME>Rasul</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Quentin</FIRSTNAME><LASTNAME>Gallou√©dec</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Hugo</FIRSTNAME><LASTNAME>Larcher</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Mathieu</FIRSTNAME><LASTNAME>Morlon</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Joshua</FIRSTNAME></AUTHOR><AUTHOR><FIRSTNAME>Vaibhav</FIRSTNAME><LASTNAME>Srivastav</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Xuan-Son</FIRSTNAME><LASTNAME>Nguyen</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Colin</FIRSTNAME><LASTNAME>Raffel</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Lewis</FIRSTNAME><LASTNAME>Tunstall</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Loubna</FIRSTNAME><MIDDLENAME>Ben</MIDDLENAME><LASTNAME>Allal</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Leandro</FIRSTNAME><LASTNAME>von Werra</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Thomas</FIRSTNAME><LASTNAME>Wolf</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>8</DAY></DATE><COMMENT>A description of SmolLM3 training recipe.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>SmolLMv3 - A Small Reasoner with Tool Use.</T><A>https://www.youtube.com/watch?v=T4XDMeoyvU0</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>41</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>9</DAY></DATE><COMMENT>The usual announcement reading and small experimentation.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Amazon</TITLE>
      <ITEM><ARTICLE><X><T>First impressions of the new Amazon Nova LLMs (via a new llm-bedrock plugin)</T><A>https://simonwillison.net/2024/Dec/4/amazon-nova/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>12</MONTH><DAY>4</DAY></DATE><COMMENT>Nova is cheaper than Gemini.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Grok</TITLE>
      <ITEM><ARTICLE><X><T>Elon Musk‚Äôs new AI model doesn‚Äôt shy from questions about cocaine and orgies</T><ST>xAI positions sarcastic AI assistant to counterbalance buttoned-up ChatGPT.</ST><A>https://arstechnica.com/information-technology/2023/11/elon-musks-new-ai-model-doesnt-shy-from-questions-about-cocaine-and-orgies/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>6</DAY></DATE><COMMENT>xAI is releasing its first chat: Grok-1.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Elon Musk‚Äôs xAI releases Grok source and weights, taunting OpenAI</T><ST>Amid criticism of OpenAI's closed models, Musk makes the Grok-1 AI model free to download.</ST><A>https://arstechnica.com/information-technology/2024/03/elon-musks-xai-releases-grok-source-and-weights-taunting-openai/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>18</DAY></DATE><COMMENT>xAI has released the weights of the Grok foundation model, but not the ones of the fine-tuned model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grokking X.ai‚Äôs Grok‚ÄîReal Advance or Just Real Troll?</T><ST>Grok-1 is the largest open-source LLM yet, though not without caveats</ST><A>https://spectrum.ieee.org/open-source-ai-grok-llm</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Matthew</FIRSTNAME><MIDDLENAME>S.</MIDDLENAME><LASTNAME>Smith</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>24</DAY></DATE><COMMENT>Some comments about Grok-1 weights availability.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Elon Musk's uncensored AI actually looks good!!!</T><A>https://www.youtube.com/watch?v=3M441UdpVXQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>14</DAY></DATE><COMMENT>The usual reading of the announcement and quick ‚Äôn dirty experiment. Grok-2 seems much better than Grok-1.5.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Musk‚Äôs new Grok upgrade allows X users to create largely uncensored AI images</T><ST>With Grok's new AI image generator, X users put Musk's "freedom of speech" to the test.</ST><A>https://arstechnica.com/information-technology/2024/08/musks-new-grok-upgrade-allows-x-users-to-create-largely-uncensored-ai-images/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>15</DAY></DATE><COMMENT>Some information about Grok-2 and its integration with Flux.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>How to use Grok API with Free Credits!!!</T><A>https://www.youtube.com/watch?v=I8-0Obq7H38</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>11</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>5</DAY></DATE><COMMENT>A slow explanation on how to use xAI‚Äôs API.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>New Grok 3 release tops LLM leaderboards despite Musk-approved ‚Äúbased‚Äù opinions</T><ST>xAI shows off new chatbot that injects a dose of Musk-flavored opinion.</ST><A>https://arstechnica.com/ai/2025/02/new-grok-3-release-tops-llm-leaderboards-despite-musk-approved-based-opinions/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><AUTHOR><FIRSTNAME>Kyle</FIRSTNAME><LASTNAME>Orland</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>18</DAY></DATE><COMMENT>A new version of <AUTHOR><FIRSTNAME>Elon</FIRSTNAME><LASTNAME>Musk</LASTNAME></AUTHOR>‚Äôs toy.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grok‚Äôs new ‚Äúunhinged‚Äù voice mode can curse and scream, simulate phone sex</T><ST>New cursing chatbot follows Elon Musk's plan to provide an "uncensored" answer to ChatGPT.</ST><A>https://arstechnica.com/ai/2025/02/groks-uncensored-ai-voice-mode-lets-users-talk-sex-therapy-and-conspiracies/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Benj</FIRSTNAME><LASTNAME>Edwards</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>26</DAY></DATE><COMMENT>The voice mode is now available.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grok 4 - 10 New Things to Know</T><A>https://www.youtube.com/watch?v=dbgL00a7_xs</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>43</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Philip</FIRSTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>10</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Philip</FIRSTNAME></AUTHOR> seems to trust benchmarks for representing the real quality of Grok. We will see‚Ä¶</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grok 4</T><A>https://simonwillison.net/2025/Jul/10/grok-4/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>10</DAY></DATE><COMMENT>Grok 4 sometimes behaves as a minion of <AUTHOR><FIRSTNAME>Elon</FIRSTNAME><LASTNAME>Musk</LASTNAME></AUTHOR>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grok 4 Heavy won't reveal its system prompt</T><A>https://simonwillison.net/2025/Jul/12/grok-4-heavy/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>12</DAY></DATE><COMMENT>xAI does not respect what they said: they do not publish their prompts.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>xAI: "We spotted a couple of issues with Grok 4 recently that we immediately investigated &amp; mitigated"</T><A>https://simonwillison.net/2025/Jul/15/xai-mitigated/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>15</DAY></DATE><COMMENT>xAI is trying to fix their prompt problems.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Grok 4 Fast</T><A>https://simonwillison.net/2025/Sep/20/grok-4-fast/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>9</MONTH><DAY>20</DAY></DATE><COMMENT>Grok 4 Fast has been released.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>MiniMax</TITLE>
      <ITEM><ARTICLE><X><T>MiniMax-01: This OPENSOURCE Model HAS LONGEST 4M CONTEXT &amp; BEATS OTHERS!</T><A>https://www.youtube.com/watch?v=NKnRPykTIJs</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>55</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>17</DAY></DATE><COMMENT>The usual quick ‚Äôn dirty announcement reading and benchmark.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>S1</TITLE>
      <ITEM><ARTICLE><X><T>S1: The $6 R1 Competitor?</T><A>https://timkellogg.me/blog/2025/02/03/s1</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Tim</FIRSTNAME><LASTNAME>Kellogg</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>3</DAY></DATE><COMMENT>How can you limit the thinking time of a model? Simply by injecting a <CODEROUTINE>&lt;/think&gt;</CODEROUTINE> token.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>S1: The $6 R1 Competitor?</T><A>https://simonwillison.net/2025/Feb/5/s1-the-6-r1-competitor/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>5</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR> is manipulating the dataset used for the s1 paper.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>s1: Simple test-time scaling: Just ‚Äúwait‚Ä¶‚Äù + 1,000 training examples? | PAPER EXPLAINED</T><A>https://www.youtube.com/watch?v=XuH2QTAC5yI</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>8</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Letitia</FIRSTNAME><LASTNAME>Parcalabescu</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>3</MONTH><DAY>23</DAY></DATE><COMMENT>A short presentation of s1‚Äôs training and how to force it to think more.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Z.ai</TITLE>
      <ITEM><ARTICLE><X><T>GLM-4.5: Reasoning, Coding, and Agentic Abililties</T><A>https://simonwillison.net/2025/Jul/28/glm-45/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>28</DAY></DATE><COMMENT>Yet another model from China.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>My 2.5 year old laptop can write Space Invaders in JavaScript now, using GLM-4.5 Air and MLX</T><A>https://simonwillison.net/2025/Jul/29/space-invaders/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>29</DAY></DATE><COMMENT>Running GLM-4.5 locally and getting it to write a Space Invaders game.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>GLM-4.5 Meets SGLang: Reasoning, Coding, and Agentic Abilities</T><A>https://lmsys.org/blog/2025-07-31-glm4-5/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>31</DAY></DATE><COMMENT>The announcement that SGLang supports GLM 4.5.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Deep Cogito</TITLE>
      <ITEM><ARTICLE><X><T>Cogito v2 Preview From inference-time search to self-improvement</T><A>https://www.deepcogito.com/research/cogito-v2-preview</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>7</MONTH><DAY>31</DAY></DATE><COMMENT>The announcement of Cogito v2 Preview from a company trying to implement self-improving models, but there are no technical details.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
  </BLIST></ITEM>
</LLIST>
</CONTENT>
</PAGE>