<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="../css/strict.xsl"?>
<PAGE xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../css/schema.xsd" xml:lang="en">
<TITLE>Mistral AI</TITLE>
<PATH>links/aimistral.xml</PATH>
<DATE><YEAR>2025</YEAR><MONTH>2</MONTH><DAY>2</DAY></DATE>
<CONTENT>
<LLIST>
  <ITEM><SLIST>
    <ITEM><X><T>Mistral AI</T><A>https://mistral.ai</A><L>en</L><F>HTML</F></X></ITEM>
  </SLIST></ITEM>
  <ITEM><BLIST><TITLE>Articles and videos</TITLE>
    <ITEM><ARTICLE><X><T>SDS 778: Mixtral 8x22B: SOTA Open-Source LLM Capabilities at a Fraction of the Compute</T><A>https://www.superdatascience.com/podcast/mixtral-8x22b-sota-open-source-llm-capabilities-at-a-fraction-of-the-compute</A><L>en</L><F>MP3</F><DURATION><MINUTE>6</MINUTE><SECOND>52</SECOND></DURATION></X><X><T>778: Mixtral 8x22B: SOTA Open-Source LLM Capabilities at a Fraction of the Compute â€” with Jon Krohn</T><A>https://www.youtube.com/watch?v=8i5s7DFAjek</A><L>en</L><F>MP4</F><DURATION><MINUTE>6</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Jon</FIRSTNAME><LASTNAME>Krohn</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>26</DAY></DATE><COMMENT>An overview of the open-weights Mistralâ€™s models.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Build, tweak, repeat</T><ST>Making it easier to develop and share generative AI applications.</ST><A>https://mistral.ai/news/build-tweak-repeat/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>8</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral introduces fine-tuning and an alpha version of agents.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>AI in abundance</T><ST>Introducing a free API, improved pricing across the board, a new enterprise-grade Mistral Small, and free vision capabilities on le Chat.</ST><A>https://mistral.ai/fr/news/september-24-release/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>A new free tier, a price cut, an update of Mistral Small, and Pixtral available on le Chat.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE predecessor="https://mistral.ai/fr/news/september-24-release/"><X quality="-1"><T>Mistral AI price cuts!!</T><A>https://www.youtube.com/watch?v=-Of4p2yOdQY</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>36</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>17</DAY></DATE><COMMENT>Reading Mistralâ€™s announcement.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Mistral Batch API</T><ST>Lower cost API for AI builders.</ST><A>https://mistral.ai/news/batch-api/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral introduces a batch mode which is 50% cheaper than the synchronous mode.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Mistral Moderation API</T><ST>We are introducing our new moderation service enabling our users to detect undesirable text content along several policy dimensions.</ST><A>https://mistral.ai/news/mistral-moderation/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>7</DAY></DATE><COMMENT>Mistral proposes an API to classify raw test or chat according to nine categories (Sexual, Hate and Discrimination, Violence and Threats, Dangerous and Criminal Content, Self-Harm, Health, Financial, Law, and PII).</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X><T>Mistral has entered the chat</T><ST>Search, vision, ideation, codingâ€¦ all yours for free.</ST><A>https://mistral.ai/fr/news/mistral-chat/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT>Le chat has some new features: web search, canvas, and integration of Pixtral Large.</COMMENT></ARTICLE></ITEM>
    <ITEM><ARTICLE><X quality="-1"><T>Mistral's FREE Coding Canvas, Search &amp; Image Gen: This BEATS Claude &amp; ChatGPT for FULLY FREE!</T><A>https://www.youtube.com/watch?v=WlRoF24bwL4</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>47</SECOND></DURATION></X><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT><AUTHOR><GIVENNAME>AICodeKing</GIVENNAME></AUTHOR> performs some very basic experimentation with the new Mistralâ€™s chat.</COMMENT></ARTICLE></ITEM>
    <ITEM><BLIST><TITLE>Mistral 7B</TITLE>
      <ITEM><ARTICLE><X><T>Is it really the best 7B model? (A First Look)</T><A>https://www.youtube.com/watch?v=3SdopNwQJ-c</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>MÄ±sra</FIRSTNAME><LASTNAME>Turp</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>9</MONTH><DAY>29</DAY></DATE><COMMENT>A short presentation of Mistral 7B model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>ðŸ¤«UNCENSORED Mistral can answer ANYTHING ðŸ¤«</T><A>https://www.youtube.com/watch?v=YPOpzJ4N25w</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>51</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>14</DAY></DATE><COMMENT>Testing <X><T>ehartford/dolphin-2.0-mistral-7b</T><A>https://huggingface.co/cognitivecomputations/dolphin-2.0-mistral-7b</A><L>en</L><F>HTML</F></X> in Google Colab.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>NOW, Zephyr 7B on Free Colab (W/o Quantization)</T><A>https://www.youtube.com/watch?v=c_S_KGRUzoY</A><L>en</L><F>MP4</F><DURATION><MINUTE>11</MINUTE><SECOND>5</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>17</DAY></DATE><COMMENT>How to use a sharded version of <X><T>HuggingFaceH4/zephyr-7b-alpha</T><A>https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha</A><L>en</L><F>HTML</F></X> in Google Collab.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>FULLY LOCAL Mistral AI PDF Processing [Hands-on Tutorial]</T><A>https://www.youtube.com/watch?v=wZDVgy_14PE</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>50</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>10</MONTH><DAY>18</DAY></DATE><COMMENT>The guy is just doing the example of <X><T>katanaml/llm-mistral-invoice-cpu</T><A>https://github.com/katanaml/llm-mistral-invoice-cpu</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mistral AI's Open Source Initiative | Arthur Mensch, Mistral AI | #aiPULSE 2023</T><A>https://www.youtube.com/watch?v=5fNtOsu3YvQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>29</MINUTE><SECOND>41</SECOND></DURATION><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>6</DAY></DATE></X><AUTHOR><FIRSTNAME>Arthur</FIRSTNAME><LASTNAME>Mensch</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>11</MONTH><DAY>17</DAY></DATE><COMMENT>The reason for creating a 7B model and some little information about its implementation.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Mistral 7B v0.2 Base: New Mistral Secrets Released at SF AI Hackathon?</T><A>https://www.youtube.com/watch?v=62gpF6Uq6Rc</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>3</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>24</DAY></DATE><COMMENT>Mistral has released a new version of their small foundation model for their San Francisco Hackathon.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>The CRAZIEST LLM Fine-Tuning I've seen, And It WORKS!!!</T><A>https://www.youtube.com/watch?v=YaXAzyUR0mE</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>3</MONTH><DAY>27</DAY></DATE><COMMENT>The Hackathon winner: Mistral 7B fine-tuned to play Doom. But this presentation is a bad as usual.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>NEW Mistral-7B v0.3 ðŸ‡«ðŸ‡· TESTED:  Uncensored, Function Calling, faster than llama3 8b?!</T><A>https://www.youtube.com/watch?v=H-vMf2VF2po</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>9</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>22</DAY></DATE><COMMENT>An inconclusive test of the latest version of Mistral-7B.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mistral's new 7B Model with Native Function Calling</T><A>https://www.youtube.com/watch?v=0T1444HJbt0</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>22</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>24</DAY></DATE><COMMENT>A better presentation of the model.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mixtral 8x7B</TITLE>
      <ITEM><ARTICLE><X><T>Mistral AI Trolls Google With 87GB T*rrent (Beats GPT4)</T><A>https://www.youtube.com/watch?v=wemHDMh2I8c</A><L>en</L><F>MP4</F><DURATION><MINUTE>8</MINUTE><SECOND>13</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>Mistral posted a torrent file for their new model, a MoE 8x7B.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mistral AI bucks release trend by dropping torrent link to new open source LLM</T><A>https://venturebeat.com/ai/mistral-ai-bucks-release-trend-by-dropping-torrent-link-to-new-open-source-llm/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Sharon</FIRSTNAME><LASTNAME>Goldman</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>8</DAY></DATE><COMMENT>The same.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>How To Run Mistral 8x7B LLM AI RIGHT NOW! (nVidia and Apple M1)</T><A>https://www.youtube.com/watch?v=5v_YhF6y_1c</A><L>en</L><F>MP4</F><DURATION><MINUTE>10</MINUTE><SECOND>29</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>10</DAY></DATE><COMMENT>People start to play with the model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mixtral of experts</T><ST>A high quality Sparse Mixture-of-Experts.</ST><A>https://mistral.ai/news/mixtral-of-experts/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>11</DAY></DATE><COMMENT>The official announcement.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mixtral 8x7B ðŸ‡«ðŸ‡· Released! - FASTEST SMoE 7B LLM on Earth ðŸŒŽðŸ”¥</T><A>https://www.youtube.com/watch?v=00vj2goPlPg</A><L>en</L><F>MP4</F><DURATION><MINUTE>7</MINUTE><SECOND>26</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>12</DAY></DATE><COMMENT>Yet another presentation of Mixtral 8x7B.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Mixtral 8x MoE vs Llama 2 70B vs Zephyr 7B vs GPT 3.5 Turbo</T><A>https://www.youtube.com/watch?v=ICYUSTwzYaU</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>30</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2023</YEAR><MONTH>12</MONTH><DAY>12</DAY></DATE><COMMENT>A quick â€™n dirty comparison of the four models.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>The NEW Mixtral 8X7B Paper is GENIUS!!!</T><A>https://www.youtube.com/watch?v=8XTHLhwX0UQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>33</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>9</DAY></DATE><COMMENT>Yet another botched presentation of a paper, this time it is "<X><T>Mixtral of Experts</T><A>https://arxiv.org/abs/2401.04088</A><L>en</L><F>HTML</F></X>".</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mixtral of Experts (Paper Explained)</T><A>https://www.youtube.com/watch?v=mwO6v4BlgZQ</A><L>en</L><F>MP4</F><DURATION><MINUTE>34</MINUTE><SECOND>31</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Yannic</FIRSTNAME><LASTNAME>Kilcher</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>1</MONTH><DAY>13</DAY></DATE><COMMENT>A better presentation of the same paper.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mixtral 8x22B</TITLE>
      <ITEM><ARTICLE><X quality="-1"><T>Mistral does it again!!!</T><A>https://www.youtube.com/watch?v=6CgeLwYUghE</A><L>en</L><F>MP4</F><DURATION><MINUTE>4</MINUTE><SECOND>44</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>10</DAY></DATE><COMMENT>The usual botched announcement of Mistralâ€™s new model: <X><T>mistral-community/Mixtral-8x22B-v0.1</T><A>https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1</A><L>en</L><F>HTML</F></X>.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>NEW Mixtral 8x22b Tested - Mistral's New Flagship MoE Open-Source Model</T><A>https://www.youtube.com/watch?v=a75TC-w2aQ4</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>2</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Matthew</FIRSTNAME><LASTNAME>Berman</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>13</DAY></DATE><COMMENT>A classic naive evaluation of the model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>MIXTRAL 8x22B INSTRUCT and more!!!</T><A>https://www.youtube.com/watch?v=nKst30LrgC4</A><L>en</L><F>MP4</F><DURATION><MINUTE>13</MINUTE><SECOND>24</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>4</MONTH><DAY>17</DAY></DATE><COMMENT>The Mixtral 8x22B Instruct model, a tokenizer, and a Python library: Mistral Common.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Codestral</TITLE>
      <ITEM><ARTICLE><X><T>Codestral: Hello, World!</T><ST>Empowering developers and democratising coding with Mistral AI.</ST><A>https://mistral.ai/news/codestral/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>5</MONTH><DAY>29</DAY></DATE><COMMENT>Mistral announces their first code model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Solving HackerRank HARD Problems with Codestral.</T><A>https://www.youtube.com/watch?v=MJ7W45iHAks</A><L>en</L><F>MP4</F><DURATION><MINUTE>12</MINUTE><SECOND>28</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>6</MONTH><DAY>4</DAY></DATE><COMMENT>The too common evaluation of a code model: the evaluator simply copies and pastes the problem and runs the unit tests, without looking at the generated code.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Codestral 25.01</T><ST>Code at the speed of Tab. Available today in Continue.dev and soon on other leading AI code assistants.</ST><A>https://mistral.ai/news/codestral-2501/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>13</DAY></DATE><COMMENT>The announcement of the new Codestral 25.01 model.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Codestral 25.01</T><A>https://simonwillison.net/2025/Jan/13/codestral-2501/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>13</DAY></DATE><COMMENT>Some little information about the new version of Codestral.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mathstral</TITLE>
      <ITEM><ARTICLE><X><T>MathÎ£tral</T><ST>As a tribute to Archimedes, whose 2311th anniversary weâ€™re celebrating this year, we are proud to release our first Mathstral model, a specific 7B model designed for math reasoning and scientific discovery. The model has a 32k context window published under the Apache 2.0 license.</ST><A>https://mistral.ai/news/mathstral/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>16</DAY></DATE><COMMENT>Mistral announces an evolution of Mistral 7B targeted at solving math problems.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Codestral Mamba</TITLE>
      <ITEM><ARTICLE><X><T>Codestral Mamba</T><ST>As a tribute to Cleopatra, whose glorious destiny ended in tragic snake circumstances, we are proud to release Codestral Mamba, a Mamba2 language model specialised in code generation, available under an Apache 2.0 license.</ST><A>https://mistral.ai/fr/news/codestral-mamba/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>16</DAY></DATE><COMMENT>The subtitle says it all.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mistral Large 2</TITLE>
      <ITEM><ARTICLE><X><T>Mistral Large 2</T><A>https://simonwillison.net/2024/Jul/24/mistral-large-2/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>24</DAY></DATE><COMMENT>Some short notes.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X quality="-1"><T>Welcome Mistral Large 2 !!!</T><A>https://www.youtube.com/watch?v=_K79cA1KW_Y</A><L>en</L><F>MP4</F><DURATION><MINUTE>15</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>7</MONTH><DAY>24</DAY></DATE><COMMENT><AUTHOR><FIRSTNAME>Abdul Majed</FIRSTNAME><LASTNAME>Raja</LASTNAME></AUTHOR> is doing his usual basic scanning though the announcement.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Pixtral</TITLE>
      <ITEM><ARTICLE><X><T>Pixtral-12B ðŸ‘€: Mistral AI's First Multi-Modal VLLM is HERE!</T><A>https://www.youtube.com/watch?v=PfzPfB3esG4</A><L>en</L><F>MP4</F><DURATION><MINUTE>14</MINUTE><SECOND>29</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>9</MONTH><DAY>11</DAY></DATE><COMMENT>The model announcement.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Ministral 3B &amp; 8B</TITLE>
      <ITEM><ARTICLE><X><T>Ministral 8B: MistralAI just released NEW 3b and 8b Agentic Models!</T><A>https://www.youtube.com/watch?v=wxl6ltSCbiM</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>34</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Noah</FIRSTNAME></AUTHOR><DATE><YEAR>2024</YEAR><MONTH>10</MONTH><DAY>16</DAY></DATE><COMMENT>The usual basic reading of the model announcement.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Pixtral Large</TITLE>
      <ITEM><ARTICLE><X><T>Pixtral Large</T><ST>Pixtral grows up.</ST><A>https://mistral.ai/fr/news/pixtral-large/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2024</YEAR><MONTH>11</MONTH><DAY>18</DAY></DATE><COMMENT>A new vision model based on Mistral Large 2.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
    <ITEM><BLIST><TITLE>Mistral Small</TITLE>
      <ITEM><ARTICLE><X><T>Mistral Small 3</T><ST>Apache 2.0, 81% MMLU, 150 tokens/s</ST><A>https://mistral.ai/news/mistral-small-3/</A><L>en</L><F>HTML</F></X><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>30</DAY></DATE><COMMENT>Mistal is promoting this updated model as fast, low-latency, with a correct accuracy level.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mistral Small 3</T><A>https://simonwillison.net/2025/Jan/30/mistral-small-3/</A><L>en</L><F>HTML</F></X><AUTHOR><FIRSTNAME>Simon</FIRSTNAME><LASTNAME>Willison</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>30</DAY></DATE><COMMENT>Some little information.</COMMENT></ARTICLE></ITEM>
      <ITEM><ARTICLE><X><T>Mistral Small 3 - The NEW Mini Model Killer</T><A>https://www.youtube.com/watch?v=nCXTdcggwkM</A><L>en</L><F>MP4</F><DURATION><MINUTE>9</MINUTE><SECOND>23</SECOND></DURATION></X><AUTHOR><FIRSTNAME>Sam</FIRSTNAME><LASTNAME>Witteveen</LASTNAME></AUTHOR><DATE><YEAR>2025</YEAR><MONTH>1</MONTH><DAY>30</DAY></DATE><COMMENT>The usual announcement reading and demo.</COMMENT></ARTICLE></ITEM>
    </BLIST></ITEM>
  </BLIST></ITEM>
</LLIST>
</CONTENT>
</PAGE>